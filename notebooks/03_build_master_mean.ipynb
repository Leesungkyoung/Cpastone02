{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a7a63181",
   "metadata": {},
   "source": [
    "# 03. Build Master Dataset (Mean Version)\n",
    "\n",
    "## ê°œìš”\n",
    "ë³¸ ë…¸íŠ¸ë¶ì€ SECOM ë°ì´í„°ì˜ **ì „ì²˜ë¦¬ ë§ˆìŠ¤í„°ì…‹(Stage A)** ì„ ìƒì„±í•©ë‹ˆë‹¤.  \n",
    "- **ëª©ì **: ê²°ì¸¡ì¹˜ ì²˜ë¦¬, ë‹¤ì¤‘ê³µì„ ì„± ì œê±°, ì´ìƒì¹˜ ì™„í™”ë¥¼ ê±°ì³ ëª¨ë¸ë§ ì¤€ë¹„ ìƒíƒœì˜ ë² ì´ìŠ¤ë¼ì¸ ë°ì´í„°ì…‹ êµ¬ì¶•\n",
    "- **ë²”ìœ„**: Stage Aë§Œ ìˆ˜í–‰ (ìŠ¤ì¼€ì¼ë§/ìƒ˜í”Œë§/Feature Selectionì€ CV ë‚´ë¶€ì—ì„œ ìˆ˜í–‰ ì˜ˆì •)\n",
    "- **ë²„ì „**: Median imputation only\n",
    "\n",
    "## ì¶œë ¥ë¬¼\n",
    "- `data/processed/base_master_mean.parquet` : ìµœì¢… ë§ˆìŠ¤í„°ì…‹\n",
    "- `data/processed/preprocess_log_mean.json` : ì „ì²˜ë¦¬ ë¡œê·¸\n",
    "- `data/interim/preview_master_mean.csv` : ìƒìœ„ 200í–‰ ë¯¸ë¦¬ë³´ê¸°"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38249935",
   "metadata": {},
   "source": [
    "### í™˜ê²½ ì„¸íŒ…"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fd682cfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pandas: 2.3.3 pyarrow: 21.0.0\n",
      "âœ“ í™˜ê²½ ì„¸íŒ… ì™„ë£Œ\n",
      "  - ì›ë³¸ ë°ì´í„°: /Users/mealkuo/Desktop/capstone02_project/data/secom_model_train.csv\n",
      "  - ì¶œë ¥ ë””ë ‰í† ë¦¬: /Users/mealkuo/Desktop/capstone02_project/data/processed\n"
     ]
    }
   ],
   "source": [
    "# í™˜ê²½ ì„¸íŒ… & ë¼ì´ë¸ŒëŸ¬ë¦¬/ê²½ë¡œ ì„ ì–¸\n",
    "import pyarrow as pa\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from pathlib import Path\n",
    "from scipy import stats\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "# ë²„ì „ í™•ì¸\n",
    "print(\"pandas:\", pd.__version__, \"pyarrow:\", pa.__version__)\n",
    "\n",
    "# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ìë™ ì„¤ì •\n",
    "ROOT = Path.cwd().parent  # notebooks í´ë”ì˜ ìƒìœ„\n",
    "\n",
    "# âœ… ì´ë¯¸ timestamp ì œê±°ëœ ë²„ì „ ì‚¬ìš©\n",
    "DATA_RAW = ROOT / 'data/secom_model_train.csv'\n",
    "\n",
    "# ë””ë ‰í† ë¦¬ ê²½ë¡œ\n",
    "DIR_INTERIM = ROOT / 'data/interim'\n",
    "DIR_PROC = ROOT / 'data/processed'\n",
    "\n",
    "# ë””ë ‰í† ë¦¬ ìƒì„± ë³´ì¥\n",
    "DIR_INTERIM.mkdir(parents=True, exist_ok=True)\n",
    "DIR_PROC.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# ì¬í˜„ì„± ì„¤ì •\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)\n",
    "\n",
    "print(\"âœ“ í™˜ê²½ ì„¸íŒ… ì™„ë£Œ\")\n",
    "print(f\"  - ì›ë³¸ ë°ì´í„°: {DATA_RAW}\")\n",
    "print(f\"  - ì¶œë ¥ ë””ë ‰í† ë¦¬: {DIR_PROC}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8afff1e6",
   "metadata": {},
   "source": [
    "## ë°ì´í„° ë¡œë“œ & ë¼ë²¨ ë§¤í•‘\n",
    "\n",
    "**ë¼ë²¨ ì¸ì½”ë”© ê·œì¹™**:\n",
    "- `-1` (Pass) â†’ `0` (ì •ìƒ)\n",
    "- `1` (Fail) â†’ `1` (ë¶ˆëŸ‰)\n",
    "- Positive class = 1 (ë¶ˆëŸ‰)\n",
    "\n",
    "ê¸°ë³¸ í†µê³„ ë° ê²°ì¸¡ë¥ ì„ í™•ì¸í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9ea86be4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì›ë³¸ ë°ì´í„° shape: (1567, 591)\n",
      "\n",
      "âœ“ ë¼ë²¨ ë§¤í•‘ ì™„ë£Œ\n",
      "  - X shape: (1567, 590)\n",
      "  - Positive class ratio: 0.0664\n",
      "  - Class distribution:\n",
      "label\n",
      "0    1463\n",
      "1     104\n",
      "Name: count, dtype: int64\n",
      "\n",
      "ê²°ì¸¡ë¥  ìƒìœ„ 10ê°œ ì»¬ëŸ¼:\n",
      "sensor_158    0.911934\n",
      "sensor_293    0.911934\n",
      "sensor_294    0.911934\n",
      "sensor_159    0.911934\n",
      "sensor_493    0.855775\n",
      "sensor_359    0.855775\n",
      "sensor_086    0.855775\n",
      "sensor_221    0.855775\n",
      "sensor_247    0.649649\n",
      "sensor_110    0.649649\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# ë°ì´í„° ë¡œë“œ & ë¼ë²¨ ë§¤í•‘\n",
    "df = pd.read_csv(DATA_RAW)\n",
    "print(f\"ì›ë³¸ ë°ì´í„° shape: {df.shape}\")\n",
    "\n",
    "# ë¼ë²¨ ë§¤í•‘: 1 -> 1 (ë¶ˆëŸ‰), -1 -> 0 (ì •ìƒ)\n",
    "label_map = {-1: 0, 1: 1}\n",
    "df['label'] = df['label'].map(label_map)\n",
    "\n",
    "# yì™€ X ë¶„ë¦¬\n",
    "y = df['label'].copy()\n",
    "X = df.drop(columns=['label'])\n",
    "\n",
    "print(f\"\\nâœ“ ë¼ë²¨ ë§¤í•‘ ì™„ë£Œ\")\n",
    "print(f\"  - X shape: {X.shape}\")\n",
    "print(f\"  - Positive class ratio: {y.mean():.4f}\")\n",
    "print(f\"  - Class distribution:\\n{y.value_counts().sort_index()}\")\n",
    "\n",
    "# ì´ˆê¸° ê²°ì¸¡ë¥  í™•ì¸\n",
    "missing_ratios = X.isnull().mean().sort_values(ascending=False)\n",
    "print(f\"\\nê²°ì¸¡ë¥  ìƒìœ„ 10ê°œ ì»¬ëŸ¼:\")\n",
    "print(missing_ratios.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aac15390",
   "metadata": {},
   "source": [
    "## ê²°ì¸¡ë¥  ê¸°ì¤€ ì»¬ëŸ¼ ì œê±°\n",
    "\n",
    "**ê¸°ì¤€**: ê²°ì¸¡ë¥  â‰¥ 0.40ì¸ ì»¬ëŸ¼ì„ ì œê±°í•©ë‹ˆë‹¤.  \n",
    "ì œê±°ëœ ì»¬ëŸ¼ ëª©ë¡ì€ ë¡œê·¸ì— ê¸°ë¡ë©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "302d1e3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ê²°ì¸¡ë¥  â‰¥ 0.4 ì»¬ëŸ¼ ìˆ˜: 32\n",
      "ì œê±° ëŒ€ìƒ ì»¬ëŸ¼ ì˜ˆì‹œ (ìµœëŒ€ 5ê°œ): ['sensor_073', 'sensor_074', 'sensor_086', 'sensor_110', 'sensor_111']\n",
      "\n",
      "âœ“ ê²°ì¸¡ë¥  ê¸°ë°˜ ì œê±° ì™„ë£Œ\n",
      "  - ë‚¨ì€ ì»¬ëŸ¼ ìˆ˜: 558\n",
      "  - ì œê±°ëœ ì»¬ëŸ¼ ìˆ˜: 32\n"
     ]
    }
   ],
   "source": [
    "# ê²°ì¸¡ë¥  ê¸°ë°˜ ì»¬ëŸ¼ ì œê±°\n",
    "MISSING_THRESHOLD = 0.40\n",
    "\n",
    "missing_ratios = X.isnull().mean()\n",
    "cols_to_drop_missing = missing_ratios[missing_ratios >= MISSING_THRESHOLD].index.tolist()\n",
    "\n",
    "print(f\"ê²°ì¸¡ë¥  â‰¥ {MISSING_THRESHOLD} ì»¬ëŸ¼ ìˆ˜: {len(cols_to_drop_missing)}\")\n",
    "if len(cols_to_drop_missing) > 0:\n",
    "    print(f\"ì œê±° ëŒ€ìƒ ì»¬ëŸ¼ ì˜ˆì‹œ (ìµœëŒ€ 5ê°œ): {cols_to_drop_missing[:5]}\")\n",
    "\n",
    "X = X.drop(columns=cols_to_drop_missing)\n",
    "print(f\"\\nâœ“ ê²°ì¸¡ë¥  ê¸°ë°˜ ì œê±° ì™„ë£Œ\")\n",
    "print(f\"  - ë‚¨ì€ ì»¬ëŸ¼ ìˆ˜: {X.shape[1]}\")\n",
    "print(f\"  - ì œê±°ëœ ì»¬ëŸ¼ ìˆ˜: {len(cols_to_drop_missing)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "271116cf",
   "metadata": {},
   "source": [
    "## ì„¼ì„œë³„ Mean / Std + Median ì‘ì„±"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "117fb199",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì „ì²˜ë¦¬ í›„ X shape: (1567, 558)\n",
      "ì„¼ì„œ ê°œìˆ˜: 558\n",
      "âœ… ì„¼ì„œë³„ mean/std/median ì €ì¥ ì™„ë£Œ!\n",
      "  ì €ì¥ ìœ„ì¹˜: ../models/sensors_mean_std_median.json\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------------------\n",
    "# ğŸ“Œ ê²°ì¸¡ë¥  í•„í„°ë§ ëë‚œ Xì—ì„œ ì„¼ì„œë³„ mean / std / median ì €ì¥\n",
    "# ------------------------------------------------------\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "# X: ìœ„ì—ì„œ ê²°ì¸¡ë¥  ê¸°ì¤€ìœ¼ë¡œ ì»¬ëŸ¼ ì œê±°ê¹Œì§€ ëë‚œ DataFrameì´ì–´ì•¼ í•¨\n",
    "print(\"ì „ì²˜ë¦¬ í›„ X shape:\", X.shape)\n",
    "\n",
    "# ê° ì„¼ì„œ(ì»¬ëŸ¼)ë³„ í†µê³„ ê³„ì‚°\n",
    "train_means   = X.mean(axis=0).to_dict()\n",
    "train_stds    = X.std(axis=0).to_dict()\n",
    "train_medians = X.median(axis=0).to_dict()\n",
    "\n",
    "print(f\"ì„¼ì„œ ê°œìˆ˜: {len(train_means)}\")\n",
    "\n",
    "# ì €ì¥ ê²½ë¡œ\n",
    "stats_path = Path(\"../models/sensors_mean_std_median.json\")\n",
    "stats_path.parent.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "# JSON êµ¬ì¡°: { \"sensor_001\": {\"mean\":..., \"std\":..., \"median\":...}, ... }\n",
    "stats_data = {}\n",
    "for col in X.columns:\n",
    "    stats_data[col] = {\n",
    "        \"mean\":   float(train_means[col]) if col in train_means else None,\n",
    "        \"std\":    float(train_stds[col]) if col in train_stds else None,\n",
    "        \"median\": float(train_medians[col]) if col in train_medians else None,\n",
    "    }\n",
    "\n",
    "with open(stats_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(stats_data, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(\"âœ… ì„¼ì„œë³„ mean/std/median ì €ì¥ ì™„ë£Œ!\")\n",
    "print(f\"  ì €ì¥ ìœ„ì¹˜: {stats_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "393cb823",
   "metadata": {},
   "source": [
    "## ê²°ì¸¡ì¹˜ Mean ëŒ€ì¹˜\n",
    "\n",
    "ë‚¨ì€ ëª¨ë“  NaN ê°’ì„ ê° í”¼ì²˜ë³„ **mean** ê°’ìœ¼ë¡œ ëŒ€ì¹˜í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ce8d7450",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ëŒ€ì¹˜ ì „ NaN ì´ ê°œìˆ˜: 8823\n",
      "\n",
      "âœ“ Mean ëŒ€ì¹˜ ì™„ë£Œ\n",
      "  - ëŒ€ì¹˜ í›„ NaN ì´ ê°œìˆ˜: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5j/xncx4f310w93nzyd92xch9jh0000gn/T/ipykernel_37337/3784397956.py:8: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X[col].fillna(mean_val, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# ê²°ì¸¡ì¹˜ mean ëŒ€ì¹˜\n",
    "nan_count_before = X.isnull().sum().sum()\n",
    "print(f\"ëŒ€ì¹˜ ì „ NaN ì´ ê°œìˆ˜: {nan_count_before}\")\n",
    "\n",
    "for col in X.columns:\n",
    "    if X[col].isnull().any():\n",
    "        mean_val = X[col].mean()\n",
    "        X[col].fillna(mean_val, inplace=True)\n",
    "\n",
    "nan_count_after = X.isnull().sum().sum()\n",
    "print(f\"\\nâœ“ Mean ëŒ€ì¹˜ ì™„ë£Œ\")\n",
    "print(f\"  - ëŒ€ì¹˜ í›„ NaN ì´ ê°œìˆ˜: {nan_count_after}\")\n",
    "assert nan_count_after == 0, \"NaNì´ ë‚¨ì•„ìˆìŠµë‹ˆë‹¤!\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71db7adf",
   "metadata": {},
   "source": [
    "## Z-score ì´ìƒì¹˜ ì™„í™”\n",
    "\n",
    "**ì „ëµ**: ê° í”¼ì²˜ì—ì„œ |z-score| > 3ì¸ ê°’ì„ í•´ë‹¹ í”¼ì²˜ì˜ medianìœ¼ë¡œ ëŒ€ì¹˜í•©ë‹ˆë‹¤.\n",
    "- ëª©ì : ê·¹ë‹¨ê°’ ì™„í™” (ì œê±°ê°€ ì•„ë‹Œ ì™„í™”)\n",
    "- í‘œì¤€í¸ì°¨ê°€ 0ì¸ ì»¬ëŸ¼ì€ ìŠ¤í‚µ\n",
    "\n",
    "=> meanì€ ì´ìƒì¹˜ì— ë¯¼ê°í•˜ê¸° ë•Œë¬¸ì—, ë™ì¼í•˜ê²Œ medianìœ¼ë¡œ ì²˜ë¦¬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fc4cf5a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Z-score ì´ìƒì¹˜ ì™„í™” ì™„ë£Œ\n",
      "  - ëŒ€ì¹˜ëœ ì´ ê°’ ê°œìˆ˜: 6065\n",
      "  - ì˜í–¥ë°›ì€ ì»¬ëŸ¼ ìˆ˜: 409\n",
      "  - ìƒìœ„ 5ê°œ ì»¬ëŸ¼: [('sensor_039', 71), ('sensor_577', 70), ('sensor_575', 68), ('sensor_578', 62), ('sensor_573', 60)]\n"
     ]
    }
   ],
   "source": [
    "# Z-score ì´ìƒì¹˜ ì™„í™”\n",
    "Z_THRESHOLD = 3\n",
    "\n",
    "outlier_replaced_counts = {}\n",
    "\n",
    "for col in X.columns:\n",
    "    col_std = X[col].std()\n",
    "    \n",
    "    # í‘œì¤€í¸ì°¨ê°€ 0ì´ë©´ ìŠ¤í‚µ\n",
    "    if col_std == 0:\n",
    "        continue\n",
    "    \n",
    "    z_scores = np.abs(stats.zscore(X[col]))\n",
    "    outliers_mask = z_scores > Z_THRESHOLD\n",
    "    outliers_count = outliers_mask.sum()\n",
    "    \n",
    "    if outliers_count > 0:\n",
    "        median_val = X[col].median()\n",
    "        X.loc[outliers_mask, col] = median_val\n",
    "        outlier_replaced_counts[col] = int(outliers_count)\n",
    "\n",
    "total_replaced = sum(outlier_replaced_counts.values())\n",
    "print(f\"âœ“ Z-score ì´ìƒì¹˜ ì™„í™” ì™„ë£Œ\")\n",
    "print(f\"  - ëŒ€ì¹˜ëœ ì´ ê°’ ê°œìˆ˜: {total_replaced}\")\n",
    "print(f\"  - ì˜í–¥ë°›ì€ ì»¬ëŸ¼ ìˆ˜: {len(outlier_replaced_counts)}\")\n",
    "if len(outlier_replaced_counts) > 0:\n",
    "    top_5 = sorted(outlier_replaced_counts.items(), key=lambda x: x[1], reverse=True)[:5]\n",
    "    print(f\"  - ìƒìœ„ 5ê°œ ì»¬ëŸ¼: {top_5}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed13f3f5",
   "metadata": {},
   "source": [
    "## ì €ë¶„ì‚°/ìƒìˆ˜ ì»¬ëŸ¼ ì œê±°\n",
    "\n",
    "**ì œê±° ê¸°ì¤€**:\n",
    "1. `VarianceThreshold(0.0)`: ë¶„ì‚°ì´ 0ì¸ ì»¬ëŸ¼\n",
    "2. ìœ ë‹ˆí¬ ê°’ì´ 1ê°œì¸ ì»¬ëŸ¼ (ì•ˆì „ë§)\n",
    "\n",
    "ë‘ ì¡°ê±´ì„ ëª¨ë‘ ì²´í¬í•˜ì—¬ ìƒìˆ˜ ì»¬ëŸ¼ì„ ì œê±°í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "289784ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì €ë¶„ì‚°/ìƒìˆ˜ ì»¬ëŸ¼ ìˆ˜: 116\n",
      "ì œê±° ëŒ€ìƒ ì»¬ëŸ¼ ì˜ˆì‹œ (ìµœëŒ€ 5ê°œ): ['sensor_539', 'sensor_263', 'sensor_330', 'sensor_243', 'sensor_326']\n",
      "\n",
      "âœ“ ì €ë¶„ì‚°/ìƒìˆ˜ ì»¬ëŸ¼ ì œê±° ì™„ë£Œ\n",
      "  - ë‚¨ì€ ì»¬ëŸ¼ ìˆ˜: 442\n",
      "  - ì œê±°ëœ ì»¬ëŸ¼ ìˆ˜: 116\n"
     ]
    }
   ],
   "source": [
    "# ì €ë¶„ì‚°/ìƒìˆ˜ ì»¬ëŸ¼ ì œê±°\n",
    "selector = VarianceThreshold(threshold=0.0)\n",
    "selector.fit(X)\n",
    "cols_variance = X.columns[selector.get_support()].tolist()\n",
    "\n",
    "# ì•ˆì „ë§: ìœ ë‹ˆí¬ê°’ì´ 1ê°œì¸ ì»¬ëŸ¼ ì¶”ê°€ ì²´í¬\n",
    "cols_unique = [col for col in X.columns if X[col].nunique() > 1]\n",
    "\n",
    "# êµì§‘í•©ìœ¼ë¡œ ìœ ì§€í•  ì»¬ëŸ¼ ê²°ì •\n",
    "cols_to_keep = list(set(cols_variance) & set(cols_unique))\n",
    "cols_to_drop_lowvar = list(set(X.columns) - set(cols_to_keep))\n",
    "\n",
    "print(f\"ì €ë¶„ì‚°/ìƒìˆ˜ ì»¬ëŸ¼ ìˆ˜: {len(cols_to_drop_lowvar)}\")\n",
    "if len(cols_to_drop_lowvar) > 0:\n",
    "    print(f\"ì œê±° ëŒ€ìƒ ì»¬ëŸ¼ ì˜ˆì‹œ (ìµœëŒ€ 5ê°œ): {cols_to_drop_lowvar[:5]}\")\n",
    "\n",
    "X = X[cols_to_keep]\n",
    "print(f\"\\nâœ“ ì €ë¶„ì‚°/ìƒìˆ˜ ì»¬ëŸ¼ ì œê±° ì™„ë£Œ\")\n",
    "print(f\"  - ë‚¨ì€ ì»¬ëŸ¼ ìˆ˜: {X.shape[1]}\")\n",
    "print(f\"  - ì œê±°ëœ ì»¬ëŸ¼ ìˆ˜: {len(cols_to_drop_lowvar)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19052c80",
   "metadata": {},
   "source": [
    "## ìƒê´€ê´€ê³„ ê¸°ë°˜ í”¼ì²˜ í•„í„°ë§ (Pre-VIF)\n",
    "\n",
    "- **ëª©ì :**  \n",
    "  ë‹¤ì¤‘ê³µì„ ì„±(VIF) ê³„ì‚° ì „ì—, ì„œë¡œ **ë„ˆë¬´ ë¹„ìŠ·í•˜ê²Œ ì›€ì§ì´ëŠ” ì„¼ì„œë“¤(ìƒê´€ê³„ìˆ˜ â‰¥ 0.95)** ì„ ë¨¼ì € ì œê±°í•˜ì—¬  \n",
    "  ì—°ì‚° ì†ë„ë¥¼ ê°œì„ í•˜ê³ , ë¶ˆí•„ìš”í•œ ì¤‘ë³µ ì‹ í˜¸ë¥¼ ì •ë¦¬í•¨.\n",
    "\n",
    "- **ë¡œì§ ìš”ì•½:**  \n",
    "  1ï¸âƒ£ ì„¼ì„œ ê°„ ìƒê´€ê³„ìˆ˜ í–‰ë ¬ ê³„ì‚° (`X.corr().abs()`)  \n",
    "  2ï¸âƒ£ ìƒì‚¼ê°í–‰ë ¬ë§Œ ë‚¨ê²¨ ì¤‘ë³µ ì œê±°  \n",
    "  3ï¸âƒ£ |r| â‰¥ 0.95 ì´ìƒì¸ ì»¬ëŸ¼ ì¤‘ í•˜ë‚˜ë¥¼ Drop  \n",
    "  4ï¸âƒ£ ë‚¨ì€ í”¼ì²˜ë“¤ë§Œ ë‹¤ìŒ ë‹¨ê³„(VIF ê¸°ë°˜ ì œê±°)ì— ì „ë‹¬\n",
    "\n",
    "- **ì´ìœ :**  \n",
    "  SECOM ì„¼ì„œ ë°ì´í„°ëŠ” ê°™ì€ ë¼ì¸ì—ì„œ ì¸¡ì •ëœ ì—°ì† í”¼ì²˜ê°€ ë§ê¸° ë•Œë¬¸ì—,  \n",
    "  ìƒê´€ê³„ìˆ˜ ê¸°ë°˜ ì„ ì œì  í•„í„°ë§ì„ í•˜ì§€ ì•Šìœ¼ë©´ **VIF ê°’ì´ í­ë°œí•˜ê±°ë‚˜ ìˆ˜ë ´ ì†ë„ê°€ ë§¤ìš° ëŠë ¤ì§ˆ ìˆ˜ ìˆìŒ.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f247897b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ìƒê´€ í•„í„°ë§ ì‹œì‘ (ì´ˆê¸° ì»¬ëŸ¼ ìˆ˜: 442)\n",
      "âœ“ 1ì°¨ ìƒê´€ í•„í„°ë§ ì™„ë£Œ\n",
      "  - ì œê±°ëœ ì»¬ëŸ¼ ìˆ˜: 92\n",
      "  - ì œê±°ëœ ì»¬ëŸ¼ ì˜ˆì‹œ (ìµœëŒ€ 5ê°œ): ['sensor_438', 'sensor_458', 'sensor_442', 'sensor_199', 'sensor_569']\n",
      "  - ë‚¨ì€ ì»¬ëŸ¼ ìˆ˜: 350\n"
     ]
    }
   ],
   "source": [
    "# =============================================\n",
    "#  ìƒê´€ê´€ê³„ ê¸°ë°˜ í”¼ì²˜ ì œê±° (VIF ì´ì „ ë‹¨ê³„)\n",
    "# =============================================\n",
    "\n",
    "print(f\"ìƒê´€ í•„í„°ë§ ì‹œì‘ (ì´ˆê¸° ì»¬ëŸ¼ ìˆ˜: {X.shape[1]})\")\n",
    "\n",
    "# ì ˆëŒ“ê°’ ìƒê´€ê³„ìˆ˜ í–‰ë ¬ ê³„ì‚°\n",
    "corr_matrix = X.corr().abs()\n",
    "\n",
    "# ìƒì‚¼ê°í–‰ë ¬ë§Œ ë‚¨ê¸°ê¸° (A-Bì™€ B-A ì¤‘ë³µ ì œê±°)\n",
    "upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "\n",
    "# ìƒê´€ê³„ìˆ˜ 0.97 ì´ìƒì¸ ì»¬ëŸ¼ ì¶”ì¶œ\n",
    "drop_corr = [column for column in upper.columns if any(upper[column] > 0.97)]\n",
    "\n",
    "# í”¼ì²˜ ì œê±°\n",
    "X = X.drop(columns=drop_corr)\n",
    "print(f\"âœ“ 1ì°¨ ìƒê´€ í•„í„°ë§ ì™„ë£Œ\")\n",
    "print(f\"  - ì œê±°ëœ ì»¬ëŸ¼ ìˆ˜: {len(drop_corr)}\")\n",
    "if len(drop_corr) > 0:\n",
    "    print(f\"  - ì œê±°ëœ ì»¬ëŸ¼ ì˜ˆì‹œ (ìµœëŒ€ 5ê°œ): {drop_corr[:5]}\")\n",
    "print(f\"  - ë‚¨ì€ ì»¬ëŸ¼ ìˆ˜: {X.shape[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f33db898",
   "metadata": {},
   "source": [
    "## VIF ê¸°ë°˜ ë‹¤ì¤‘ê³µì„ ì„± ì œê±°\n",
    "\n",
    "**ì „ëµ**: VIF > 10ì¸ ì»¬ëŸ¼ì„ ë°˜ë³µì ìœ¼ë¡œ ì œê±°í•©ë‹ˆë‹¤.\n",
    "- ë§¤ ë°˜ë³µë§ˆë‹¤ ê°€ì¥ ë†’ì€ VIFë¥¼ ê°€ì§„ ì»¬ëŸ¼ 1ê°œë¥¼ ì œê±°\n",
    "- ëª¨ë“  VIF â‰¤ 10ì´ ë˜ê±°ë‚˜ ìµœëŒ€ ë°˜ë³µ íšŸìˆ˜ì— ë„ë‹¬í•˜ë©´ ì¤‘ë‹¨\n",
    "- ìµœëŒ€ ë°˜ë³µ: 100íšŒ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bae55003",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VIF ì œê±° ì‹œì‘ (ì´ˆê¸° ì»¬ëŸ¼ ìˆ˜: 350)\n",
      "  ë°˜ë³µ 10: Max VIF = 178909.22, ì œê±°ëœ ì»¬ëŸ¼ ìˆ˜ = 10\n",
      "  ë°˜ë³µ 20: Max VIF = 58302.19, ì œê±°ëœ ì»¬ëŸ¼ ìˆ˜ = 20\n",
      "  ë°˜ë³µ 30: Max VIF = 15719.95, ì œê±°ëœ ì»¬ëŸ¼ ìˆ˜ = 30\n",
      "  ë°˜ë³µ 40: Max VIF = 8727.60, ì œê±°ëœ ì»¬ëŸ¼ ìˆ˜ = 40\n",
      "  ë°˜ë³µ 50: Max VIF = 3394.02, ì œê±°ëœ ì»¬ëŸ¼ ìˆ˜ = 50\n",
      "  ë°˜ë³µ 60: Max VIF = 1274.52, ì œê±°ëœ ì»¬ëŸ¼ ìˆ˜ = 60\n",
      "  ë°˜ë³µ 70: Max VIF = 706.65, ì œê±°ëœ ì»¬ëŸ¼ ìˆ˜ = 70\n",
      "  ë°˜ë³µ 80: Max VIF = 451.75, ì œê±°ëœ ì»¬ëŸ¼ ìˆ˜ = 80\n",
      "  ë°˜ë³µ 90: Max VIF = 306.02, ì œê±°ëœ ì»¬ëŸ¼ ìˆ˜ = 90\n",
      "  ë°˜ë³µ 100: Max VIF = 202.06, ì œê±°ëœ ì»¬ëŸ¼ ìˆ˜ = 100\n",
      "\n",
      "âœ“ VIF ì œê±° ì™„ë£Œ\n",
      "  - ë‚¨ì€ ì»¬ëŸ¼ ìˆ˜: 250\n",
      "  - ì œê±°ëœ ì»¬ëŸ¼ ìˆ˜: 100\n",
      "  - ì œê±°ëœ ì»¬ëŸ¼ ì˜ˆì‹œ (ìµœëŒ€ 5ê°œ): ['sensor_122', 'sensor_132', 'sensor_051', 'sensor_058', 'sensor_071']\n"
     ]
    }
   ],
   "source": [
    "# VIF ê¸°ë°˜ ë‹¤ì¤‘ê³µì„ ì„± ì œê±°\n",
    "VIF_THRESHOLD = 10\n",
    "MAX_ITER = 100\n",
    "\n",
    "X_vif = X.copy()\n",
    "dropped_vif_cols = []\n",
    "\n",
    "print(f\"VIF ì œê±° ì‹œì‘ (ì´ˆê¸° ì»¬ëŸ¼ ìˆ˜: {X_vif.shape[1]})\")\n",
    "\n",
    "for iteration in range(MAX_ITER):\n",
    "    vif_data = pd.DataFrame()\n",
    "    vif_data['Feature'] = X_vif.columns\n",
    "    vif_data['VIF'] = [variance_inflation_factor(X_vif.values, i) for i in range(X_vif.shape[1])]\n",
    "    \n",
    "    max_vif = vif_data['VIF'].max()\n",
    "    \n",
    "    if max_vif <= VIF_THRESHOLD:\n",
    "        print(f\"  ë°˜ë³µ {iteration}: ëª¨ë“  VIF â‰¤ {VIF_THRESHOLD} ë‹¬ì„±\")\n",
    "        break\n",
    "    \n",
    "    # ê°€ì¥ ë†’ì€ VIF ì»¬ëŸ¼ ì œê±°\n",
    "    col_to_drop = vif_data.loc[vif_data['VIF'].idxmax(), 'Feature']\n",
    "    dropped_vif_cols.append(col_to_drop)\n",
    "    X_vif = X_vif.drop(columns=[col_to_drop])\n",
    "    \n",
    "    if (iteration + 1) % 10 == 0:\n",
    "        print(f\"  ë°˜ë³µ {iteration + 1}: Max VIF = {max_vif:.2f}, ì œê±°ëœ ì»¬ëŸ¼ ìˆ˜ = {len(dropped_vif_cols)}\")\n",
    "\n",
    "X = X_vif\n",
    "print(f\"\\nâœ“ VIF ì œê±° ì™„ë£Œ\")\n",
    "print(f\"  - ë‚¨ì€ ì»¬ëŸ¼ ìˆ˜: {X.shape[1]}\")\n",
    "print(f\"  - ì œê±°ëœ ì»¬ëŸ¼ ìˆ˜: {len(dropped_vif_cols)}\")\n",
    "if len(dropped_vif_cols) > 0:\n",
    "    print(f\"  - ì œê±°ëœ ì»¬ëŸ¼ ì˜ˆì‹œ (ìµœëŒ€ 5ê°œ): {dropped_vif_cols[:5]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1fc4610",
   "metadata": {},
   "source": [
    "##  IQR ê¸°ë°˜ ë…¸ì´ì¦ˆ ë“œë¡­\n",
    "\n",
    "**ë¡œì§**:\n",
    "1. ì§€ì •ëœ ì»¬ëŸ¼ì— ëŒ€í•´ Q1 - 1.5Ã—IQR, Q3 + 1.5Ã—IQR ë²”ìœ„ ë°– ê°’ì„ NaNìœ¼ë¡œ ë§ˆí‚¹\n",
    "2. í•´ë‹¹ ì»¬ëŸ¼ì˜ ê²°ì¸¡ë¥ ì´ â‰¥ 0.50ì´ë©´ ì»¬ëŸ¼ ìì²´ë¥¼ ì œê±°\n",
    "\n",
    "=> ì„¼ì„œ ë‹¨ìœ„ í’ˆì§ˆ ê´€ë¦¬ QCì— í•´ë‹¹ë˜ë¯€ë¡œ, ì„¼ì„œê°€ ì•„ì˜ˆ ë¶ˆì•ˆì •í•´ì„œ ë°ì´í„°ì˜ ì ˆë°˜ì´ ì—‰ë§ì¸ ê²½ìš° ì„¼ì„œ ìì²´ê°€ ë¬¸ì œì´ë¯€ë¡œ ì„¼ì„œë¥¼ ì—†ì• ëŠ” ê²ƒ\n",
    "\n",
    "â‘  Stage Aì—ì„œ ì´ë¯¸ ì´ìƒì¹˜ ì™„í™”(Z-score) ë¥¼ í–ˆê¸° ë•Œë¬¸\n",
    "\n",
    "â‘¡ SECOM ë°ì´í„° ìì²´ê°€ ê²°ì¸¡ ë¹„ìœ¨ ë‚®ìŒ\n",
    "\n",
    "Stage Aì—ì„œ 40% ì´ìƒ ê²°ì¸¡ ë“œëí–ˆìœ¼ë‹ˆê¹Œ ë‚¨ì€ ì»¬ëŸ¼ë“¤ì—” ê²°ì¸¡ì´ ê±°ì˜ ì—†ê³ , IQRë¡œ NaN ë§ˆí‚¹í•´ë„ 0.5 ë¹„ìœ¨ ë„˜ëŠ” ì»¬ëŸ¼ì´ ì•ˆ ë‚˜ì˜´.\n",
    "\n",
    "\n",
    "**ê¸°ë³¸ê°’**: ë¹ˆ ë¦¬ìŠ¤íŠ¸ (ë¯¸ì ìš©)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bfa75e12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ IQR ë…¸ì´ì¦ˆ ë“œë¡­ ìŠ¤í‚µ (ë…¸ì´ì¦ˆ ì»¬ëŸ¼ ëª©ë¡ ë¹„ì–´ìˆìŒ)\n",
      "  - ì œê±°ëœ ì»¬ëŸ¼ ìˆ˜: 0\n"
     ]
    }
   ],
   "source": [
    "# (ì˜µì…˜) IQR ê¸°ë°˜ ë…¸ì´ì¦ˆ ë“œë¡­\n",
    "NOISE_COLS = []  # ê¸°ë³¸: ë¹„ì–´ìˆìŒ (ë¯¸ì ìš©)\n",
    "IQR_MISSING_THRESHOLD = 0.50\n",
    "\n",
    "dropped_iqr_cols = []\n",
    "\n",
    "if len(NOISE_COLS) > 0:\n",
    "    print(f\"IQR ë…¸ì´ì¦ˆ ë“œë¡­ ì ìš© ëŒ€ìƒ: {len(NOISE_COLS)}ê°œ ì»¬ëŸ¼\")\n",
    "    \n",
    "    for col in NOISE_COLS:\n",
    "        if col not in X.columns:\n",
    "            continue\n",
    "        \n",
    "        Q1 = X[col].quantile(0.25)\n",
    "        Q3 = X[col].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        \n",
    "        lower_bound = Q1 - 1.5 * IQR\n",
    "        upper_bound = Q3 + 1.5 * IQR\n",
    "        \n",
    "        # ë²”ìœ„ ë°– ê°’ì„ NaNìœ¼ë¡œ ë§ˆí‚¹\n",
    "        X.loc[(X[col] < lower_bound) | (X[col] > upper_bound), col] = np.nan\n",
    "        \n",
    "        # ê²°ì¸¡ë¥  ì²´í¬\n",
    "        missing_ratio = X[col].isnull().mean()\n",
    "        if missing_ratio >= IQR_MISSING_THRESHOLD:\n",
    "            dropped_iqr_cols.append(col)\n",
    "    \n",
    "    # ê³ ê²°ì¸¡ ì»¬ëŸ¼ ì œê±°\n",
    "    if len(dropped_iqr_cols) > 0:\n",
    "        X = X.drop(columns=dropped_iqr_cols)\n",
    "        print(f\"  - IQR í›„ ê³ ê²°ì¸¡ ì»¬ëŸ¼ ì œê±°: {len(dropped_iqr_cols)}ê°œ\")\n",
    "    \n",
    "    # ë‚¨ì€ NaNì„ medianìœ¼ë¡œ ì¬ëŒ€ì¹˜\n",
    "    for col in X.columns:\n",
    "        if X[col].isnull().any():\n",
    "            X[col].fillna(X[col].median(), inplace=True)\n",
    "    \n",
    "    print(f\"âœ“ IQR ë…¸ì´ì¦ˆ ë“œë¡­ ì™„ë£Œ\")\n",
    "else:\n",
    "    print(\"âœ“ IQR ë…¸ì´ì¦ˆ ë“œë¡­ ìŠ¤í‚µ (ë…¸ì´ì¦ˆ ì»¬ëŸ¼ ëª©ë¡ ë¹„ì–´ìˆìŒ)\")\n",
    "\n",
    "print(f\"  - ì œê±°ëœ ì»¬ëŸ¼ ìˆ˜: {len(dropped_iqr_cols)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0aca72a",
   "metadata": {},
   "source": [
    "## ì €ì¥ & ë¡œê·¸ ê¸°ë¡\n",
    "\n",
    "**ì €ì¥ íŒŒì¼**:\n",
    "- `base_master_median.parquet`: ìµœì¢… ì „ì²˜ë¦¬ ë°ì´í„°ì…‹ (X + y)\n",
    "- `preprocess_log_median.json`: ì „ì²˜ë¦¬ ë¡œê·¸ (ë“œë¡­/ëŒ€ì¹˜ ë‚´ì—­)\n",
    "- `preview_master_median.csv`: ìƒìœ„ 200í–‰ ë¯¸ë¦¬ë³´ê¸°\n",
    "\n",
    "**ë¡œê·¸ í¬í•¨ í•­ëª©**:\n",
    "- ê° ë‹¨ê³„ë³„ ì œê±°ëœ ì»¬ëŸ¼ ëª©ë¡\n",
    "- ì´ìƒì¹˜ ëŒ€ì¹˜ í†µê³„\n",
    "- ìµœì¢… shape ë° positive ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "24e726ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ ìµœì¢… ë°ì´í„°ì…‹ ì €ì¥: /Users/mealkuo/Desktop/capstone02_project/data/processed/base_master_mean.parquet\n",
      "  - Shape: (1567, 251)\n",
      "âœ“ ì „ì²˜ë¦¬ ë¡œê·¸ ì €ì¥: /Users/mealkuo/Desktop/capstone02_project/data/processed/preprocess_log_mean.json\n",
      "âœ“ ë¯¸ë¦¬ë³´ê¸° ì €ì¥: /Users/mealkuo/Desktop/capstone02_project/data/interim/preview_master_mean.csv\n",
      "\n",
      "============================================================\n",
      "ì „ì²˜ë¦¬ ì™„ë£Œ ìš”ì•½\n",
      "============================================================\n",
      "ìµœì¢… ì»¬ëŸ¼ ìˆ˜: 250 (+ label)\n",
      "ìµœì¢… ìƒ˜í”Œ ìˆ˜: 1567\n",
      "Positive ratio: 0.0664\n",
      "\n",
      "ì œê±°ëœ ì»¬ëŸ¼ ì´ê³„:\n",
      "  - ê²°ì¸¡ë¥ : 32\n",
      "  - ì €ë¶„ì‚°: 116\n",
      "  - VIF: 100\n",
      "  - IQR: 0\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# ì €ì¥ & ë¡œê·¸ ê¸°ë¡\n",
    "# ìµœì¢… ë°ì´í„°ì…‹ ê²°í•©\n",
    "df_final = X.copy()\n",
    "df_final['label'] = y.values\n",
    "\n",
    "# Parquet ì €ì¥\n",
    "output_parquet = DIR_PROC / 'base_master_mean.parquet'\n",
    "df_final.to_parquet(output_parquet, index=False)\n",
    "print(f\"âœ“ ìµœì¢… ë°ì´í„°ì…‹ ì €ì¥: {output_parquet}\")\n",
    "print(f\"  - Shape: {df_final.shape}\")\n",
    "\n",
    "# ë¡œê·¸ ìƒì„±\n",
    "log_data = {\n",
    "    'version': 'mean',\n",
    "    'dropped_missing_cols': cols_to_drop_missing,\n",
    "    'dropped_lowvar': cols_to_drop_lowvar,\n",
    "    'dropped_vif': dropped_vif_cols,\n",
    "    'dropped_iqr': dropped_iqr_cols,\n",
    "    'outlier_replaced_counts': outlier_replaced_counts,\n",
    "    'final_shape': {\n",
    "        'rows': int(df_final.shape[0]),\n",
    "        'cols': int(df_final.shape[1])\n",
    "    },\n",
    "    'positive_ratio': float(y.mean()),\n",
    "    'preprocessing_steps': [\n",
    "        'label_encoding',\n",
    "        'missing_ratio_drop',\n",
    "        'man_imputation',\n",
    "        'low_variance_drop',\n",
    "        'vif_multicollinearity',\n",
    "        'zscore_outlier_mitigation',\n",
    "        'iqr_noise_drop'\n",
    "    ]\n",
    "}\n",
    "\n",
    "# ë¡œê·¸ ì €ì¥\n",
    "output_log = DIR_PROC / 'preprocess_log_mean.json'\n",
    "with open(output_log, 'w', encoding='utf-8') as f:\n",
    "    json.dump(log_data, f, indent=2, ensure_ascii=False)\n",
    "print(f\"âœ“ ì „ì²˜ë¦¬ ë¡œê·¸ ì €ì¥: {output_log}\")\n",
    "\n",
    "# ë¯¸ë¦¬ë³´ê¸° ì €ì¥ (ìƒìœ„ 200í–‰)\n",
    "output_preview = DIR_INTERIM / 'preview_master_mean.csv'\n",
    "df_final.head(200).to_csv(output_preview, index=False)\n",
    "print(f\"âœ“ ë¯¸ë¦¬ë³´ê¸° ì €ì¥: {output_preview}\")\n",
    "\n",
    "# ìš”ì•½ ì¶œë ¥\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ì „ì²˜ë¦¬ ì™„ë£Œ ìš”ì•½\")\n",
    "print(\"=\"*60)\n",
    "print(f\"ìµœì¢… ì»¬ëŸ¼ ìˆ˜: {df_final.shape[1] - 1} (+ label)\")\n",
    "print(f\"ìµœì¢… ìƒ˜í”Œ ìˆ˜: {df_final.shape[0]}\")\n",
    "print(f\"Positive ratio: {y.mean():.4f}\")\n",
    "print(f\"\\nì œê±°ëœ ì»¬ëŸ¼ ì´ê³„:\")\n",
    "print(f\"  - ê²°ì¸¡ë¥ : {len(cols_to_drop_missing)}\")\n",
    "print(f\"  - ì €ë¶„ì‚°: {len(cols_to_drop_lowvar)}\")\n",
    "print(f\"  - VIF: {len(dropped_vif_cols)}\")\n",
    "print(f\"  - IQR: {len(dropped_iqr_cols)}\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4a3441f",
   "metadata": {},
   "source": [
    "## ë¹ ë¥¸ ê²€ì¦ ì²´í¬\n",
    "\n",
    "ë°ì´í„° í’ˆì§ˆì„ ìµœì¢… í™•ì¸í•©ë‹ˆë‹¤:\n",
    "- NaN ì”ì—¬ ì—¬ë¶€\n",
    "- ì»¬ëŸ¼ ìˆ˜ ë³€í™”\n",
    "- ë¼ë²¨ ë¶„í¬\n",
    "- ê¸°ë³¸ í†µê³„ëŸ‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7861bc60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ê²€ì¦ ì²´í¬]\n",
      "============================================================\n",
      "1. NaN ì´ ê°œìˆ˜: 0\n",
      "   âœ“ NaN ì—†ìŒ í™•ì¸\n",
      "\n",
      "2. ì»¬ëŸ¼ ìˆ˜ (ë¼ë²¨ ì œì™¸): 250\n",
      "   - ì›ë³¸ ì»¬ëŸ¼ ìˆ˜ì™€ ë¹„êµí•˜ì—¬ ê°ì†Œ í™•ì¸\n",
      "\n",
      "3. ë¼ë²¨ ë¶„í¬:\n",
      "label\n",
      "0    1463\n",
      "1     104\n",
      "Name: count, dtype: int64\n",
      "   - Positive ratio: 0.0664\n",
      "\n",
      "4. ê¸°ë³¸ í†µê³„ëŸ‰ (ì²« 5ê°œ í”¼ì²˜):\n",
      "      sensor_081  sensor_486  sensor_171  sensor_239  sensor_291\n",
      "mean   -0.018531  185.823012    0.684330    0.004723    0.098236\n",
      "std     0.048847  192.898602    0.157418    0.001448    0.056613\n",
      "min    -0.143700    0.000000    0.297900    0.001300    0.041600\n",
      "max     0.118600  850.602400    1.153000    0.009800    0.552800\n",
      "\n",
      "============================================================\n",
      "âœ“ ëª¨ë“  ê²€ì¦ í†µê³¼\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# ë¹ ë¥¸ ê²€ì¦ ì²´í¬\n",
    "print(\"[ê²€ì¦ ì²´í¬]\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# 1. NaN ì²´í¬\n",
    "nan_sum = df_final.isnull().sum().sum()\n",
    "print(f\"1. NaN ì´ ê°œìˆ˜: {nan_sum}\")\n",
    "assert nan_sum == 0, \"âš ï¸  NaNì´ ë‚¨ì•„ìˆìŠµë‹ˆë‹¤!\"\n",
    "print(\"   âœ“ NaN ì—†ìŒ í™•ì¸\")\n",
    "\n",
    "# 2. ì»¬ëŸ¼ ìˆ˜ í™•ì¸\n",
    "print(f\"\\n2. ì»¬ëŸ¼ ìˆ˜ (ë¼ë²¨ ì œì™¸): {df_final.shape[1] - 1}\")\n",
    "print(f\"   - ì›ë³¸ ì»¬ëŸ¼ ìˆ˜ì™€ ë¹„êµí•˜ì—¬ ê°ì†Œ í™•ì¸\")\n",
    "\n",
    "# 3. ë¼ë²¨ ë¶„í¬\n",
    "print(f\"\\n3. ë¼ë²¨ ë¶„í¬:\")\n",
    "print(df_final['label'].value_counts().sort_index())\n",
    "print(f\"   - Positive ratio: {df_final['label'].mean():.4f}\")\n",
    "\n",
    "# 4. ê¸°ë³¸ í†µê³„ëŸ‰ (ì¼ë¶€)\n",
    "print(f\"\\n4. ê¸°ë³¸ í†µê³„ëŸ‰ (ì²« 5ê°œ í”¼ì²˜):\")\n",
    "print(df_final.iloc[:, :5].describe().loc[['mean', 'std', 'min', 'max']])\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"âœ“ ëª¨ë“  ê²€ì¦ í†µê³¼\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a81ab2fc",
   "metadata": {},
   "source": [
    "### ì¶”ê°€ ìˆ˜ì •\n",
    "\n",
    "â‘¡ ìƒê´€ í•„í„°ë§ ë“œë ë¦¬ìŠ¤íŠ¸ë¥¼ ë¡œê·¸ì— ì¶”ê°€\n",
    "\n",
    "â‘¢ ë¡œê·¸ & íŒŒì¼ ë‹¤ì‹œ ì €ì¥\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ee13043d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ ë¡œê·¸ ê°±ì‹  ì™„ë£Œ\n"
     ]
    }
   ],
   "source": [
    "log_data = {\n",
    "    'version': 'mean',\n",
    "    'dropped_missing_cols': cols_to_drop_missing,\n",
    "    'dropped_lowvar': cols_to_drop_lowvar,\n",
    "    'dropped_corr': drop_corr,  # âœ… ì¶”ê°€\n",
    "    'dropped_vif': dropped_vif_cols,\n",
    "    'dropped_iqr': dropped_iqr_cols,\n",
    "    'outlier_replaced_counts': outlier_replaced_counts,\n",
    "    'final_shape': {\n",
    "        'rows': int(df_final.shape[0]),\n",
    "        'cols': int(df_final.shape[1])\n",
    "    },\n",
    "    'positive_ratio': float(df_final['label'].mean()),\n",
    "    'preprocessing_steps': [\n",
    "        'label_encoding',\n",
    "        'missing_ratio_drop',\n",
    "        'mean_imputation',\n",
    "        'low_variance_drop',\n",
    "        'correlation_filter',   # âœ… ì¶”ê°€\n",
    "        'vif_multicollinearity',\n",
    "        'zscore_outlier_mitigation',\n",
    "        'iqr_noise_drop'\n",
    "    ]\n",
    "}\n",
    "\n",
    "# ë®ì–´ ì“°ê¸° ì €ì¥\n",
    "output_log = DIR_PROC / 'preprocess_log_mean.json'\n",
    "with open(output_log, 'w', encoding='utf-8') as f:\n",
    "    json.dump(log_data, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(\"âœ“ ë¡œê·¸ ê°±ì‹  ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5d41b23",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (capstone02)",
   "language": "python",
   "name": "capstone02"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
