{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a7a63181",
   "metadata": {},
   "source": [
    "# 03. Build Master Dataset (Mean Version)\n",
    "\n",
    "## 개요\n",
    "본 노트북은 SECOM 데이터의 **전처리 마스터셋(Stage A)** 을 생성합니다.  \n",
    "- **목적**: 결측치 처리, 다중공선성 제거, 이상치 완화를 거쳐 모델링 준비 상태의 베이스라인 데이터셋 구축\n",
    "- **범위**: Stage A만 수행 (스케일링/샘플링/Feature Selection은 CV 내부에서 수행 예정)\n",
    "- **버전**: Median imputation only\n",
    "\n",
    "## 출력물\n",
    "- `data/processed/base_master_mean.parquet` : 최종 마스터셋\n",
    "- `data/processed/preprocess_log_mean.json` : 전처리 로그\n",
    "- `data/interim/preview_master_mean.csv` : 상위 200행 미리보기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38249935",
   "metadata": {},
   "source": [
    "### 환경 세팅"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd682cfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pandas: 2.3.3 pyarrow: 21.0.0\n",
      "✓ 환경 세팅 완료\n",
      "  - 원본 데이터: /Users/mealkuo/Desktop/capstone02_project/data/secom_model_train.csv\n",
      "  - 출력 디렉토리: /Users/mealkuo/Desktop/capstone02_project/data/processed\n"
     ]
    }
   ],
   "source": [
    "# 환경 세팅 & 라이브러리/경로 선언\n",
    "import pyarrow as pa\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from pathlib import Path\n",
    "from scipy import stats\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "# 버전 확인\n",
    "print(\"pandas:\", pd.__version__, \"pyarrow:\", pa.__version__)\n",
    "\n",
    "# 프로젝트 루트 자동 설정\n",
    "ROOT = Path.cwd().parent  # notebooks 폴더의 상위\n",
    "\n",
    "# ✅ 이미 timestamp 제거된 버전 사용\n",
    "DATA_RAW = ROOT / 'data/secom_model_train.csv'\n",
    "\n",
    "# 디렉토리 경로\n",
    "DIR_INTERIM = ROOT / 'data/interim'\n",
    "DIR_PROC = ROOT / 'data/processed'\n",
    "\n",
    "# 디렉토리 생성 보장\n",
    "DIR_INTERIM.mkdir(parents=True, exist_ok=True)\n",
    "DIR_PROC.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# 재현성 설정\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)\n",
    "\n",
    "print(\"✓ 환경 세팅 완료\")\n",
    "print(f\"  - 원본 데이터: {DATA_RAW}\")\n",
    "print(f\"  - 출력 디렉토리: {DIR_PROC}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8afff1e6",
   "metadata": {},
   "source": [
    "## 데이터 로드 & 라벨 매핑\n",
    "\n",
    "**라벨 인코딩 규칙**:\n",
    "- `-1` (Pass) → `0` (정상)\n",
    "- `1` (Fail) → `1` (불량)\n",
    "- Positive class = 1 (불량)\n",
    "\n",
    "기본 통계 및 결측률을 확인합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9ea86be4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원본 데이터 shape: (1567, 591)\n",
      "\n",
      "✓ 라벨 매핑 완료\n",
      "  - X shape: (1567, 590)\n",
      "  - Positive class ratio: 0.0664\n",
      "  - Class distribution:\n",
      "label\n",
      "0    1463\n",
      "1     104\n",
      "Name: count, dtype: int64\n",
      "\n",
      "결측률 상위 10개 컬럼:\n",
      "sensor_158    0.911934\n",
      "sensor_293    0.911934\n",
      "sensor_294    0.911934\n",
      "sensor_159    0.911934\n",
      "sensor_493    0.855775\n",
      "sensor_359    0.855775\n",
      "sensor_086    0.855775\n",
      "sensor_221    0.855775\n",
      "sensor_247    0.649649\n",
      "sensor_110    0.649649\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# 데이터 로드 & 라벨 매핑\n",
    "df = pd.read_csv(DATA_RAW)\n",
    "print(f\"원본 데이터 shape: {df.shape}\")\n",
    "\n",
    "# 라벨 매핑: 1 -> 1 (불량), -1 -> 0 (정상)\n",
    "label_map = {-1: 0, 1: 1}\n",
    "df['label'] = df['label'].map(label_map)\n",
    "\n",
    "# y와 X 분리\n",
    "y = df['label'].copy()\n",
    "X = df.drop(columns=['label'])\n",
    "\n",
    "print(f\"\\n✓ 라벨 매핑 완료\")\n",
    "print(f\"  - X shape: {X.shape}\")\n",
    "print(f\"  - Positive class ratio: {y.mean():.4f}\")\n",
    "print(f\"  - Class distribution:\\n{y.value_counts().sort_index()}\")\n",
    "\n",
    "# 초기 결측률 확인\n",
    "missing_ratios = X.isnull().mean().sort_values(ascending=False)\n",
    "print(f\"\\n결측률 상위 10개 컬럼:\")\n",
    "print(missing_ratios.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aac15390",
   "metadata": {},
   "source": [
    "## 결측률 기준 컬럼 제거\n",
    "\n",
    "**기준**: 결측률 ≥ 0.40인 컬럼을 제거합니다.  \n",
    "제거된 컬럼 목록은 로그에 기록됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "302d1e3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "결측률 ≥ 0.4 컬럼 수: 32\n",
      "제거 대상 컬럼 예시 (최대 5개): ['sensor_073', 'sensor_074', 'sensor_086', 'sensor_110', 'sensor_111']\n",
      "\n",
      "✓ 결측률 기반 제거 완료\n",
      "  - 남은 컬럼 수: 558\n",
      "  - 제거된 컬럼 수: 32\n"
     ]
    }
   ],
   "source": [
    "# 결측률 기반 컬럼 제거\n",
    "MISSING_THRESHOLD = 0.40\n",
    "\n",
    "missing_ratios = X.isnull().mean()\n",
    "cols_to_drop_missing = missing_ratios[missing_ratios >= MISSING_THRESHOLD].index.tolist()\n",
    "\n",
    "print(f\"결측률 ≥ {MISSING_THRESHOLD} 컬럼 수: {len(cols_to_drop_missing)}\")\n",
    "if len(cols_to_drop_missing) > 0:\n",
    "    print(f\"제거 대상 컬럼 예시 (최대 5개): {cols_to_drop_missing[:5]}\")\n",
    "\n",
    "X = X.drop(columns=cols_to_drop_missing)\n",
    "print(f\"\\n✓ 결측률 기반 제거 완료\")\n",
    "print(f\"  - 남은 컬럼 수: {X.shape[1]}\")\n",
    "print(f\"  - 제거된 컬럼 수: {len(cols_to_drop_missing)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "393cb823",
   "metadata": {},
   "source": [
    "## 결측치 Mean 대치\n",
    "\n",
    "남은 모든 NaN 값을 각 피처별 **mean** 값으로 대치합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ce8d7450",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "대치 전 NaN 총 개수: 8823\n",
      "\n",
      "✓ Mean 대치 완료\n",
      "  - 대치 후 NaN 총 개수: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5j/xncx4f310w93nzyd92xch9jh0000gn/T/ipykernel_37337/3784397956.py:8: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X[col].fillna(mean_val, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# 결측치 mean 대치\n",
    "nan_count_before = X.isnull().sum().sum()\n",
    "print(f\"대치 전 NaN 총 개수: {nan_count_before}\")\n",
    "\n",
    "for col in X.columns:\n",
    "    if X[col].isnull().any():\n",
    "        mean_val = X[col].mean()\n",
    "        X[col].fillna(mean_val, inplace=True)\n",
    "\n",
    "nan_count_after = X.isnull().sum().sum()\n",
    "print(f\"\\n✓ Mean 대치 완료\")\n",
    "print(f\"  - 대치 후 NaN 총 개수: {nan_count_after}\")\n",
    "assert nan_count_after == 0, \"NaN이 남아있습니다!\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71db7adf",
   "metadata": {},
   "source": [
    "## Z-score 이상치 완화\n",
    "\n",
    "**전략**: 각 피처에서 |z-score| > 3인 값을 해당 피처의 median으로 대치합니다.\n",
    "- 목적: 극단값 완화 (제거가 아닌 완화)\n",
    "- 표준편차가 0인 컬럼은 스킵\n",
    "\n",
    "=> mean은 이상치에 민감하기 때문에, 동일하게 median으로 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fc4cf5a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Z-score 이상치 완화 완료\n",
      "  - 대치된 총 값 개수: 6065\n",
      "  - 영향받은 컬럼 수: 409\n",
      "  - 상위 5개 컬럼: [('sensor_039', 71), ('sensor_577', 70), ('sensor_575', 68), ('sensor_578', 62), ('sensor_573', 60)]\n"
     ]
    }
   ],
   "source": [
    "# Z-score 이상치 완화\n",
    "Z_THRESHOLD = 3\n",
    "\n",
    "outlier_replaced_counts = {}\n",
    "\n",
    "for col in X.columns:\n",
    "    col_std = X[col].std()\n",
    "    \n",
    "    # 표준편차가 0이면 스킵\n",
    "    if col_std == 0:\n",
    "        continue\n",
    "    \n",
    "    z_scores = np.abs(stats.zscore(X[col]))\n",
    "    outliers_mask = z_scores > Z_THRESHOLD\n",
    "    outliers_count = outliers_mask.sum()\n",
    "    \n",
    "    if outliers_count > 0:\n",
    "        median_val = X[col].median()\n",
    "        X.loc[outliers_mask, col] = median_val\n",
    "        outlier_replaced_counts[col] = int(outliers_count)\n",
    "\n",
    "total_replaced = sum(outlier_replaced_counts.values())\n",
    "print(f\"✓ Z-score 이상치 완화 완료\")\n",
    "print(f\"  - 대치된 총 값 개수: {total_replaced}\")\n",
    "print(f\"  - 영향받은 컬럼 수: {len(outlier_replaced_counts)}\")\n",
    "if len(outlier_replaced_counts) > 0:\n",
    "    top_5 = sorted(outlier_replaced_counts.items(), key=lambda x: x[1], reverse=True)[:5]\n",
    "    print(f\"  - 상위 5개 컬럼: {top_5}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed13f3f5",
   "metadata": {},
   "source": [
    "## 저분산/상수 컬럼 제거\n",
    "\n",
    "**제거 기준**:\n",
    "1. `VarianceThreshold(0.0)`: 분산이 0인 컬럼\n",
    "2. 유니크 값이 1개인 컬럼 (안전망)\n",
    "\n",
    "두 조건을 모두 체크하여 상수 컬럼을 제거합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "289784ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "저분산/상수 컬럼 수: 116\n",
      "제거 대상 컬럼 예시 (최대 5개): ['sensor_539', 'sensor_263', 'sensor_330', 'sensor_243', 'sensor_326']\n",
      "\n",
      "✓ 저분산/상수 컬럼 제거 완료\n",
      "  - 남은 컬럼 수: 442\n",
      "  - 제거된 컬럼 수: 116\n"
     ]
    }
   ],
   "source": [
    "# 저분산/상수 컬럼 제거\n",
    "selector = VarianceThreshold(threshold=0.0)\n",
    "selector.fit(X)\n",
    "cols_variance = X.columns[selector.get_support()].tolist()\n",
    "\n",
    "# 안전망: 유니크값이 1개인 컬럼 추가 체크\n",
    "cols_unique = [col for col in X.columns if X[col].nunique() > 1]\n",
    "\n",
    "# 교집합으로 유지할 컬럼 결정\n",
    "cols_to_keep = list(set(cols_variance) & set(cols_unique))\n",
    "cols_to_drop_lowvar = list(set(X.columns) - set(cols_to_keep))\n",
    "\n",
    "print(f\"저분산/상수 컬럼 수: {len(cols_to_drop_lowvar)}\")\n",
    "if len(cols_to_drop_lowvar) > 0:\n",
    "    print(f\"제거 대상 컬럼 예시 (최대 5개): {cols_to_drop_lowvar[:5]}\")\n",
    "\n",
    "X = X[cols_to_keep]\n",
    "print(f\"\\n✓ 저분산/상수 컬럼 제거 완료\")\n",
    "print(f\"  - 남은 컬럼 수: {X.shape[1]}\")\n",
    "print(f\"  - 제거된 컬럼 수: {len(cols_to_drop_lowvar)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19052c80",
   "metadata": {},
   "source": [
    "## 상관관계 기반 피처 필터링 (Pre-VIF)\n",
    "\n",
    "- **목적:**  \n",
    "  다중공선성(VIF) 계산 전에, 서로 **너무 비슷하게 움직이는 센서들(상관계수 ≥ 0.95)** 을 먼저 제거하여  \n",
    "  연산 속도를 개선하고, 불필요한 중복 신호를 정리함.\n",
    "\n",
    "- **로직 요약:**  \n",
    "  1️⃣ 센서 간 상관계수 행렬 계산 (`X.corr().abs()`)  \n",
    "  2️⃣ 상삼각행렬만 남겨 중복 제거  \n",
    "  3️⃣ |r| ≥ 0.95 이상인 컬럼 중 하나를 Drop  \n",
    "  4️⃣ 남은 피처들만 다음 단계(VIF 기반 제거)에 전달\n",
    "\n",
    "- **이유:**  \n",
    "  SECOM 센서 데이터는 같은 라인에서 측정된 연속 피처가 많기 때문에,  \n",
    "  상관계수 기반 선제적 필터링을 하지 않으면 **VIF 값이 폭발하거나 수렴 속도가 매우 느려질 수 있음.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f247897b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "상관 필터링 시작 (초기 컬럼 수: 442)\n",
      "✓ 1차 상관 필터링 완료\n",
      "  - 제거된 컬럼 수: 92\n",
      "  - 제거된 컬럼 예시 (최대 5개): ['sensor_438', 'sensor_458', 'sensor_442', 'sensor_199', 'sensor_569']\n",
      "  - 남은 컬럼 수: 350\n"
     ]
    }
   ],
   "source": [
    "# =============================================\n",
    "#  상관관계 기반 피처 제거 (VIF 이전 단계)\n",
    "# =============================================\n",
    "\n",
    "print(f\"상관 필터링 시작 (초기 컬럼 수: {X.shape[1]})\")\n",
    "\n",
    "# 절댓값 상관계수 행렬 계산\n",
    "corr_matrix = X.corr().abs()\n",
    "\n",
    "# 상삼각행렬만 남기기 (A-B와 B-A 중복 제거)\n",
    "upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "\n",
    "# 상관계수 0.97 이상인 컬럼 추출\n",
    "drop_corr = [column for column in upper.columns if any(upper[column] > 0.97)]\n",
    "\n",
    "# 피처 제거\n",
    "X = X.drop(columns=drop_corr)\n",
    "print(f\"✓ 1차 상관 필터링 완료\")\n",
    "print(f\"  - 제거된 컬럼 수: {len(drop_corr)}\")\n",
    "if len(drop_corr) > 0:\n",
    "    print(f\"  - 제거된 컬럼 예시 (최대 5개): {drop_corr[:5]}\")\n",
    "print(f\"  - 남은 컬럼 수: {X.shape[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f33db898",
   "metadata": {},
   "source": [
    "## VIF 기반 다중공선성 제거\n",
    "\n",
    "**전략**: VIF > 10인 컬럼을 반복적으로 제거합니다.\n",
    "- 매 반복마다 가장 높은 VIF를 가진 컬럼 1개를 제거\n",
    "- 모든 VIF ≤ 10이 되거나 최대 반복 횟수에 도달하면 중단\n",
    "- 최대 반복: 100회"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bae55003",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VIF 제거 시작 (초기 컬럼 수: 350)\n",
      "  반복 10: Max VIF = 178909.22, 제거된 컬럼 수 = 10\n",
      "  반복 20: Max VIF = 58302.19, 제거된 컬럼 수 = 20\n",
      "  반복 30: Max VIF = 15719.95, 제거된 컬럼 수 = 30\n",
      "  반복 40: Max VIF = 8727.60, 제거된 컬럼 수 = 40\n",
      "  반복 50: Max VIF = 3394.02, 제거된 컬럼 수 = 50\n",
      "  반복 60: Max VIF = 1274.52, 제거된 컬럼 수 = 60\n",
      "  반복 70: Max VIF = 706.65, 제거된 컬럼 수 = 70\n",
      "  반복 80: Max VIF = 451.75, 제거된 컬럼 수 = 80\n",
      "  반복 90: Max VIF = 306.02, 제거된 컬럼 수 = 90\n",
      "  반복 100: Max VIF = 202.06, 제거된 컬럼 수 = 100\n",
      "\n",
      "✓ VIF 제거 완료\n",
      "  - 남은 컬럼 수: 250\n",
      "  - 제거된 컬럼 수: 100\n",
      "  - 제거된 컬럼 예시 (최대 5개): ['sensor_122', 'sensor_132', 'sensor_051', 'sensor_058', 'sensor_071']\n"
     ]
    }
   ],
   "source": [
    "# VIF 기반 다중공선성 제거\n",
    "VIF_THRESHOLD = 10\n",
    "MAX_ITER = 100\n",
    "\n",
    "X_vif = X.copy()\n",
    "dropped_vif_cols = []\n",
    "\n",
    "print(f\"VIF 제거 시작 (초기 컬럼 수: {X_vif.shape[1]})\")\n",
    "\n",
    "for iteration in range(MAX_ITER):\n",
    "    vif_data = pd.DataFrame()\n",
    "    vif_data['Feature'] = X_vif.columns\n",
    "    vif_data['VIF'] = [variance_inflation_factor(X_vif.values, i) for i in range(X_vif.shape[1])]\n",
    "    \n",
    "    max_vif = vif_data['VIF'].max()\n",
    "    \n",
    "    if max_vif <= VIF_THRESHOLD:\n",
    "        print(f\"  반복 {iteration}: 모든 VIF ≤ {VIF_THRESHOLD} 달성\")\n",
    "        break\n",
    "    \n",
    "    # 가장 높은 VIF 컬럼 제거\n",
    "    col_to_drop = vif_data.loc[vif_data['VIF'].idxmax(), 'Feature']\n",
    "    dropped_vif_cols.append(col_to_drop)\n",
    "    X_vif = X_vif.drop(columns=[col_to_drop])\n",
    "    \n",
    "    if (iteration + 1) % 10 == 0:\n",
    "        print(f\"  반복 {iteration + 1}: Max VIF = {max_vif:.2f}, 제거된 컬럼 수 = {len(dropped_vif_cols)}\")\n",
    "\n",
    "X = X_vif\n",
    "print(f\"\\n✓ VIF 제거 완료\")\n",
    "print(f\"  - 남은 컬럼 수: {X.shape[1]}\")\n",
    "print(f\"  - 제거된 컬럼 수: {len(dropped_vif_cols)}\")\n",
    "if len(dropped_vif_cols) > 0:\n",
    "    print(f\"  - 제거된 컬럼 예시 (최대 5개): {dropped_vif_cols[:5]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1fc4610",
   "metadata": {},
   "source": [
    "##  IQR 기반 노이즈 드롭\n",
    "\n",
    "**로직**:\n",
    "1. 지정된 컬럼에 대해 Q1 - 1.5×IQR, Q3 + 1.5×IQR 범위 밖 값을 NaN으로 마킹\n",
    "2. 해당 컬럼의 결측률이 ≥ 0.50이면 컬럼 자체를 제거\n",
    "\n",
    "=> 센서 단위 품질 관리 QC에 해당되므로, 센서가 아예 불안정해서 데이터의 절반이 엉망인 경우 센서 자체가 문제이므로 센서를 없애는 것\n",
    "\n",
    "① Stage A에서 이미 이상치 완화(Z-score) 를 했기 때문\n",
    "\n",
    "② SECOM 데이터 자체가 결측 비율 낮음\n",
    "\n",
    "Stage A에서 40% 이상 결측 드랍했으니까 남은 컬럼들엔 결측이 거의 없고, IQR로 NaN 마킹해도 0.5 비율 넘는 컬럼이 안 나옴.\n",
    "\n",
    "\n",
    "**기본값**: 빈 리스트 (미적용)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bfa75e12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ IQR 노이즈 드롭 스킵 (노이즈 컬럼 목록 비어있음)\n",
      "  - 제거된 컬럼 수: 0\n"
     ]
    }
   ],
   "source": [
    "# (옵션) IQR 기반 노이즈 드롭\n",
    "NOISE_COLS = []  # 기본: 비어있음 (미적용)\n",
    "IQR_MISSING_THRESHOLD = 0.50\n",
    "\n",
    "dropped_iqr_cols = []\n",
    "\n",
    "if len(NOISE_COLS) > 0:\n",
    "    print(f\"IQR 노이즈 드롭 적용 대상: {len(NOISE_COLS)}개 컬럼\")\n",
    "    \n",
    "    for col in NOISE_COLS:\n",
    "        if col not in X.columns:\n",
    "            continue\n",
    "        \n",
    "        Q1 = X[col].quantile(0.25)\n",
    "        Q3 = X[col].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        \n",
    "        lower_bound = Q1 - 1.5 * IQR\n",
    "        upper_bound = Q3 + 1.5 * IQR\n",
    "        \n",
    "        # 범위 밖 값을 NaN으로 마킹\n",
    "        X.loc[(X[col] < lower_bound) | (X[col] > upper_bound), col] = np.nan\n",
    "        \n",
    "        # 결측률 체크\n",
    "        missing_ratio = X[col].isnull().mean()\n",
    "        if missing_ratio >= IQR_MISSING_THRESHOLD:\n",
    "            dropped_iqr_cols.append(col)\n",
    "    \n",
    "    # 고결측 컬럼 제거\n",
    "    if len(dropped_iqr_cols) > 0:\n",
    "        X = X.drop(columns=dropped_iqr_cols)\n",
    "        print(f\"  - IQR 후 고결측 컬럼 제거: {len(dropped_iqr_cols)}개\")\n",
    "    \n",
    "    # 남은 NaN을 median으로 재대치\n",
    "    for col in X.columns:\n",
    "        if X[col].isnull().any():\n",
    "            X[col].fillna(X[col].median(), inplace=True)\n",
    "    \n",
    "    print(f\"✓ IQR 노이즈 드롭 완료\")\n",
    "else:\n",
    "    print(\"✓ IQR 노이즈 드롭 스킵 (노이즈 컬럼 목록 비어있음)\")\n",
    "\n",
    "print(f\"  - 제거된 컬럼 수: {len(dropped_iqr_cols)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0aca72a",
   "metadata": {},
   "source": [
    "## 저장 & 로그 기록\n",
    "\n",
    "**저장 파일**:\n",
    "- `base_master_median.parquet`: 최종 전처리 데이터셋 (X + y)\n",
    "- `preprocess_log_median.json`: 전처리 로그 (드롭/대치 내역)\n",
    "- `preview_master_median.csv`: 상위 200행 미리보기\n",
    "\n",
    "**로그 포함 항목**:\n",
    "- 각 단계별 제거된 컬럼 목록\n",
    "- 이상치 대치 통계\n",
    "- 최종 shape 및 positive ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "24e726ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ 최종 데이터셋 저장: /Users/mealkuo/Desktop/capstone02_project/data/processed/base_master_mean.parquet\n",
      "  - Shape: (1567, 251)\n",
      "✓ 전처리 로그 저장: /Users/mealkuo/Desktop/capstone02_project/data/processed/preprocess_log_mean.json\n",
      "✓ 미리보기 저장: /Users/mealkuo/Desktop/capstone02_project/data/interim/preview_master_mean.csv\n",
      "\n",
      "============================================================\n",
      "전처리 완료 요약\n",
      "============================================================\n",
      "최종 컬럼 수: 250 (+ label)\n",
      "최종 샘플 수: 1567\n",
      "Positive ratio: 0.0664\n",
      "\n",
      "제거된 컬럼 총계:\n",
      "  - 결측률: 32\n",
      "  - 저분산: 116\n",
      "  - VIF: 100\n",
      "  - IQR: 0\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# 저장 & 로그 기록\n",
    "# 최종 데이터셋 결합\n",
    "df_final = X.copy()\n",
    "df_final['label'] = y.values\n",
    "\n",
    "# Parquet 저장\n",
    "output_parquet = DIR_PROC / 'base_master_mean.parquet'\n",
    "df_final.to_parquet(output_parquet, index=False)\n",
    "print(f\"✓ 최종 데이터셋 저장: {output_parquet}\")\n",
    "print(f\"  - Shape: {df_final.shape}\")\n",
    "\n",
    "# 로그 생성\n",
    "log_data = {\n",
    "    'version': 'mean',\n",
    "    'dropped_missing_cols': cols_to_drop_missing,\n",
    "    'dropped_lowvar': cols_to_drop_lowvar,\n",
    "    'dropped_vif': dropped_vif_cols,\n",
    "    'dropped_iqr': dropped_iqr_cols,\n",
    "    'outlier_replaced_counts': outlier_replaced_counts,\n",
    "    'final_shape': {\n",
    "        'rows': int(df_final.shape[0]),\n",
    "        'cols': int(df_final.shape[1])\n",
    "    },\n",
    "    'positive_ratio': float(y.mean()),\n",
    "    'preprocessing_steps': [\n",
    "        'label_encoding',\n",
    "        'missing_ratio_drop',\n",
    "        'man_imputation',\n",
    "        'low_variance_drop',\n",
    "        'vif_multicollinearity',\n",
    "        'zscore_outlier_mitigation',\n",
    "        'iqr_noise_drop'\n",
    "    ]\n",
    "}\n",
    "\n",
    "# 로그 저장\n",
    "output_log = DIR_PROC / 'preprocess_log_mean.json'\n",
    "with open(output_log, 'w', encoding='utf-8') as f:\n",
    "    json.dump(log_data, f, indent=2, ensure_ascii=False)\n",
    "print(f\"✓ 전처리 로그 저장: {output_log}\")\n",
    "\n",
    "# 미리보기 저장 (상위 200행)\n",
    "output_preview = DIR_INTERIM / 'preview_master_mean.csv'\n",
    "df_final.head(200).to_csv(output_preview, index=False)\n",
    "print(f\"✓ 미리보기 저장: {output_preview}\")\n",
    "\n",
    "# 요약 출력\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"전처리 완료 요약\")\n",
    "print(\"=\"*60)\n",
    "print(f\"최종 컬럼 수: {df_final.shape[1] - 1} (+ label)\")\n",
    "print(f\"최종 샘플 수: {df_final.shape[0]}\")\n",
    "print(f\"Positive ratio: {y.mean():.4f}\")\n",
    "print(f\"\\n제거된 컬럼 총계:\")\n",
    "print(f\"  - 결측률: {len(cols_to_drop_missing)}\")\n",
    "print(f\"  - 저분산: {len(cols_to_drop_lowvar)}\")\n",
    "print(f\"  - VIF: {len(dropped_vif_cols)}\")\n",
    "print(f\"  - IQR: {len(dropped_iqr_cols)}\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4a3441f",
   "metadata": {},
   "source": [
    "## 빠른 검증 체크\n",
    "\n",
    "데이터 품질을 최종 확인합니다:\n",
    "- NaN 잔여 여부\n",
    "- 컬럼 수 변화\n",
    "- 라벨 분포\n",
    "- 기본 통계량"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7861bc60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[검증 체크]\n",
      "============================================================\n",
      "1. NaN 총 개수: 0\n",
      "   ✓ NaN 없음 확인\n",
      "\n",
      "2. 컬럼 수 (라벨 제외): 250\n",
      "   - 원본 컬럼 수와 비교하여 감소 확인\n",
      "\n",
      "3. 라벨 분포:\n",
      "label\n",
      "0    1463\n",
      "1     104\n",
      "Name: count, dtype: int64\n",
      "   - Positive ratio: 0.0664\n",
      "\n",
      "4. 기본 통계량 (첫 5개 피처):\n",
      "      sensor_081  sensor_486  sensor_171  sensor_239  sensor_291\n",
      "mean   -0.018531  185.823012    0.684330    0.004723    0.098236\n",
      "std     0.048847  192.898602    0.157418    0.001448    0.056613\n",
      "min    -0.143700    0.000000    0.297900    0.001300    0.041600\n",
      "max     0.118600  850.602400    1.153000    0.009800    0.552800\n",
      "\n",
      "============================================================\n",
      "✓ 모든 검증 통과\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# 빠른 검증 체크\n",
    "print(\"[검증 체크]\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# 1. NaN 체크\n",
    "nan_sum = df_final.isnull().sum().sum()\n",
    "print(f\"1. NaN 총 개수: {nan_sum}\")\n",
    "assert nan_sum == 0, \"⚠️  NaN이 남아있습니다!\"\n",
    "print(\"   ✓ NaN 없음 확인\")\n",
    "\n",
    "# 2. 컬럼 수 확인\n",
    "print(f\"\\n2. 컬럼 수 (라벨 제외): {df_final.shape[1] - 1}\")\n",
    "print(f\"   - 원본 컬럼 수와 비교하여 감소 확인\")\n",
    "\n",
    "# 3. 라벨 분포\n",
    "print(f\"\\n3. 라벨 분포:\")\n",
    "print(df_final['label'].value_counts().sort_index())\n",
    "print(f\"   - Positive ratio: {df_final['label'].mean():.4f}\")\n",
    "\n",
    "# 4. 기본 통계량 (일부)\n",
    "print(f\"\\n4. 기본 통계량 (첫 5개 피처):\")\n",
    "print(df_final.iloc[:, :5].describe().loc[['mean', 'std', 'min', 'max']])\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"✓ 모든 검증 통과\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a81ab2fc",
   "metadata": {},
   "source": [
    "### 추가 수정\n",
    "\n",
    "② 상관 필터링 드랍 리스트를 로그에 추가\n",
    "\n",
    "③ 로그 & 파일 다시 저장\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ee13043d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ 로그 갱신 완료\n"
     ]
    }
   ],
   "source": [
    "log_data = {\n",
    "    'version': 'mean',\n",
    "    'dropped_missing_cols': cols_to_drop_missing,\n",
    "    'dropped_lowvar': cols_to_drop_lowvar,\n",
    "    'dropped_corr': drop_corr,  # ✅ 추가\n",
    "    'dropped_vif': dropped_vif_cols,\n",
    "    'dropped_iqr': dropped_iqr_cols,\n",
    "    'outlier_replaced_counts': outlier_replaced_counts,\n",
    "    'final_shape': {\n",
    "        'rows': int(df_final.shape[0]),\n",
    "        'cols': int(df_final.shape[1])\n",
    "    },\n",
    "    'positive_ratio': float(df_final['label'].mean()),\n",
    "    'preprocessing_steps': [\n",
    "        'label_encoding',\n",
    "        'missing_ratio_drop',\n",
    "        'mean_imputation',\n",
    "        'low_variance_drop',\n",
    "        'correlation_filter',   # ✅ 추가\n",
    "        'vif_multicollinearity',\n",
    "        'zscore_outlier_mitigation',\n",
    "        'iqr_noise_drop'\n",
    "    ]\n",
    "}\n",
    "\n",
    "# 덮어 쓰기 저장\n",
    "output_log = DIR_PROC / 'preprocess_log_mean.json'\n",
    "with open(output_log, 'w', encoding='utf-8') as f:\n",
    "    json.dump(log_data, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(\"✓ 로그 갱신 완료\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28319eb4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "capstone02",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
