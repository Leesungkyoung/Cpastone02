import streamlit as st
st.set_page_config(layout="wide")

import pandas as pd
import numpy as np
import plotly.graph_objects as go
from pathlib import Path

from src.backend import model_ab
from src.backend import summary as backend_summary  # í•„ìš”í•˜ë©´

# =====================================================================================
# 1. ë°ì´í„° ìƒì„± (Dummy Data Generation)
# =====================================================================================
@st.cache_data
def generate_model_ab_data():
    # --- Feature Analysis Tab Data ---
    # ğŸ”¥ Feature Importance (Lasso vs RandomForest) â€” ì‹¤ì œ Top-40 ê²°ê³¼ ì‚¬ìš©
    feat_dict = model_ab.get_feature_importance_top40()
    importance_lasso = feat_dict["lasso"]   # pd.DataFrame
    importance_rf = feat_dict["rf"]         # pd.DataFrame

    # ì‹¤ì œ ì•ˆì •ì„± ì ìˆ˜ ì‚¬ìš©
    stability_scores = model_ab.get_stability_scores()

    # ==========================================================
    # --- Baseline Model Tab Data (ì§„ì§œ CSV ê²°ê³¼ ì‚¬ìš©) ---
    #   Model A : capstone02_project_final ìª½ ê²°ê³¼
    #   Model B : capstone02_project(ì„±ê²½) ìª½ ê²°ê³¼
    # ==========================================================
    # Model A ê²½ë¡œ (Median + RobustScaler íŒŒì´í”„ë¼ì¸)
    BASE_DIR = Path(__file__).resolve().parents[2]
    path_model_a = BASE_DIR / "results" / "final" / "metrics_summary_baseline.csv"

    # Model B ê²½ë¡œ (Mean + StandardScaler íŒŒì´í”„ë¼ì¸)
    path_model_b = BASE_DIR / "results" / "final" / "metrics_summary_baseline(mean).csv"

    df_a = pd.read_csv(path_model_a)
    df_b = pd.read_csv(path_model_b)

    # íˆíŠ¸ë§µì— ì‚¬ìš©í•  ëª¨ë¸ / ìƒ˜í”Œë§ ìˆœì„œ (baseline ë…¸íŠ¸ë¶ì—ì„œ ì“°ë˜ ìˆœì„œ ê¸°ì¤€)
    models_order = ["DecisionTree", "LinearSVM", "LogisticRegression"]
    sampling_order = ["RUS", "SMOTE", "SMOTE+Tomek"]

    def make_heatmaps_one_model(df: pd.DataFrame):
        """í•œ íŒŒì´í”„ë¼ì¸(df)ì— ëŒ€í•´ Recall / F1 / AUC-PR íˆíŠ¸ë§µ 3ê°œ ìƒì„±"""
        def _pivot(metric_col: str) -> pd.DataFrame:
            pivot = (
                df.pivot(index="Model", columns="Sampling", values=metric_col)
                  .loc[models_order, sampling_order]
            )
            return pivot

        return {
            "Recall": _pivot("Recall"),
            "F1-score": _pivot("F1"),
            "AUC-PR": _pivot("AUC_PR"),
        }

    # Model A / Bìš© íˆíŠ¸ë§µ ë°ì´í„°
    heatmaps_a = make_heatmaps_one_model(df_a)
    heatmaps_b = make_heatmaps_one_model(df_b)

    # ğŸ‘‰ Baseline ì„±ëŠ¥ ìš”ì•½ìš© (ê° íŒŒì´í”„ë¼ì¸ì—ì„œ F1ì´ ê°€ì¥ ë†’ì€ ì¡°í•© í•˜ë‚˜ì”© ì„ íƒ)
    def summarize_best_row(df: pd.DataFrame):
        best = df.loc[df["F1"].idxmax()]
        return {
            "Recall": float(best["Recall"]),
            "F1": float(best["F1"]),
            "AUC-PR": float(best["AUC_PR"]),
        }

    sum_a = summarize_best_row(df_a)
    sum_b = summarize_best_row(df_b)

    baseline_perf = pd.DataFrame({
        "Metric": ["Recall", "F1-Score", "AUC-PR"],
        "Model A": [sum_a["Recall"], sum_a["F1"], sum_a["AUC-PR"]],
        "Model B": [sum_b["Recall"], sum_b["F1"], sum_b["AUC-PR"]],
    })

        # --- Advanced Model Tab Data (ìš”ì•½ìš©: ë‘ íŒŒì´í”„ë¼ì¸ ìµœì  ì¡°í•© ë¹„êµ) ---
    # baselineì—ì„œ ë½‘ì€ ìµœì  ì¡°í•©(sum_a, sum_b)ì„ Advanced íƒ­ ìš”ì•½ì—ë„ ì¬ì‚¬ìš©
    advanced_perf = pd.DataFrame({
        "Metric": ["Recall", "F1-Score", "AUC-PR"],
        "Model A": [sum_a["Recall"], sum_a["F1"], sum_a["AUC-PR"]],
        "Model B": [sum_b["Recall"], sum_b["F1"], sum_b["AUC-PR"]],
    })


          # Model A / Bìš© íˆíŠ¸ë§µ ë°ì´í„°
    heatmaps_a = make_heatmaps_one_model(df_a)
    heatmaps_b = make_heatmaps_one_model(df_b)

    # ğŸ‘‰ íƒ­2(ë¶ˆê· í˜• ì²˜ë¦¬ íˆíŠ¸ë§µ)ì—ì„œ ê¸°ë³¸ìœ¼ë¡œ ì‚¬ìš©í•  3Ã—3 íˆíŠ¸ë§µì€ Model A ê¸°ì¤€ìœ¼ë¡œ ì‚¬ìš©
    heatmap_recall = heatmaps_a["Recall"]      # 3Ã—3 DataFrame
    heatmap_f1 = heatmaps_a["F1-score"]        # 3Ã—3 DataFrame
    heatmap_aucpr = heatmaps_a["AUC-PR"]       # 3Ã—3 DataFrame
 


    experiment_setup = pd.DataFrame([
        {"Category": "Feature Selection", "Method": "Top-60 + mRMR", "Details": "Top-40ì—ì„œ ì¶”ê°€ í™•ì¥í•˜ì—¬ ëª¨ë¸ ì•ˆì •ì„±ê³¼ ì¬í˜„ìœ¨ í–¥ìƒ ì‹œë„"},
        {"Category": "Sampling", "Method": "SMOTE-ENN", "Details": "ê³¼ìƒ˜í”Œë§+ì–¸ë”ìƒ˜í”Œë§ í˜¼í•©ìœ¼ë¡œ ê²½ê³„ë¶€ ë…¸ì´ì¦ˆ ì œê±° ë° ë¶„ë¦¬ë„ í–¥ìƒ"},
        {"Category": "Model", "Method": "LightGBM", "Details": "ë¶ˆê· í˜• ë°ì´í„° ë° ìˆ˜ì¹˜í˜• Featureì— ê°•ì , ë¹ ë¥¸ í•™ìŠµ ì†ë„"},
        {"Category": "Tuning", "Method": "Bayesian Optimization", "Details": "ì£¼ìš” í•˜ì´í¼íŒŒë¼ë¯¸í„°ë¥¼ íš¨ìœ¨ì ìœ¼ë¡œ íƒìƒ‰í•˜ì—¬ ìµœì  ì¡°í•© ë°œê²¬"},
    ])

    return {
        # íƒ­1ìš©
        "importance_lasso": importance_lasso,
        "importance_rf": importance_rf,
        "stability_scores": stability_scores,
        # íƒ­2 íˆíŠ¸ë§µìš© (Model ì„ íƒ + ì§€í‘œ ì„ íƒì— ë”°ë¼ ì“¸ ê±°)
        "baseline_heatmap_a": heatmaps_a,
        "baseline_heatmap_b": heatmaps_b,
        # íƒ­2 ìš”ì•½ë°” / metric ì¹´ë“œìš©
        "baseline_perf": baseline_perf,
        "advanced_perf": advanced_perf,
        # íƒ­3
        "experiment_setup": experiment_setup,
        "heatmap_recall": heatmap_recall,
        "heatmap_f1": heatmap_f1,
        "heatmap_aucpr": heatmap_aucpr,
    }


data = generate_model_ab_data()

# =====================================================================================
# 2. í˜ì´ì§€ ë Œë”ë§
# =====================================================================================
def render():
    st.header("Model A & Model B")
    
    tab1, tab2, tab3 = st.tabs([
        "Feature Analysis", 
        "Baseline Model", 
        "Advanced Model"
    ])

    # ---------------------------------------------------------------------------------
    # TAB 1: Feature Analysis
    # ---------------------------------------------------------------------------------
    with tab1:
        st.subheader("Feature Analysis")
        st.markdown("Lassoì™€ RandomForest ê¸°ë°˜ Feature ì¤‘ìš”ë„ì™€ ì•ˆì •ì„±ì„ ë¹„êµí•˜ì—¬ í•µì‹¬ Featureë“¤ì„ ë¶„ì„í•©ë‹ˆë‹¤.")
        st.markdown("---")
        
        # --- Layout: 2x2 Grid ---
        col1, col2 = st.columns(2)

        with col1:
            st.markdown("##### Feature Importance (Lasso vs RandomForest)")
            
            # Selectbox for controlling other charts
            importance_method = st.selectbox(
                "Feature Importance ê¸°ì¤€ (ì˜† 'Top-10' ì°¨íŠ¸ì— ì ìš©)", 
                ["Lasso", "RandomForest"]
            )

            # Side-by-side bar charts
            sub_col1, sub_col2 = st.columns(2)

            with sub_col1:
                df_lasso = data['importance_lasso'].head(20).sort_values('importance', ascending=True)
                fig_lasso = go.Figure(go.Bar(
                    x=df_lasso['importance'],
                    y=df_lasso['feature'],
                    orientation='h',
                    name='Lasso',
                    marker=dict(color='indianred'),
                    text=df_lasso['importance'],        # ë§‰ëŒ€ì— ê°’ ë¼ë²¨
                    textposition='outside'              # ë§‰ëŒ€ ë°”ê¹¥ì— í‘œì‹œ
                ))

                fig_lasso.update_layout(
                    title='Lasso Importance',
                    height=400,
                    margin=dict(l=10, r=10, t=30, b=10),
                    plot_bgcolor="white",               # ê·¸ë˜í”„ ë°°ê²½
                    paper_bgcolor="rgba(0,0,0,0)",      # ë°”ê¹¥ ë°°ê²½(íˆ¬ëª…)
                    xaxis=dict(
                        showline=True,
                        linewidth=1,
                        linecolor="black"
                    ),
                    yaxis=dict(
                        showline=True,
                        linewidth=1,
                        linecolor="black",
                        showticklabels=True           # ê¸°ì¡´ì²˜ëŸ¼ ì„¼ì„œ ì´ë¦„ì€ ì˜¤ë¥¸ìª½ í° ê·¸ë˜í”„ì—ì„œë§Œ
                    )
                )

                fig_lasso.update_xaxes(
                    tickmode="linear",
                    tick0=0,
                    dtick=1,                            # 0,1,2,3,4,5 ëˆˆê¸ˆ
                    showgrid=True,
                    gridwidth=1
                )

                st.plotly_chart(fig_lasso, use_container_width=True)

        with sub_col2:
            df_rf = data['importance_rf'].head(20).sort_values('importance', ascending=True)
            fig_rf = go.Figure(go.Bar(
                x=df_rf['importance'],
                y=df_rf['feature'],
                orientation='h',
                name='RandomForest',
                marker=dict(color='lightsalmon'),
                text=df_rf['importance'],           # ë¼ë²¨
                textposition='outside'
            ))

            fig_rf.update_layout(
                title='RandomForest Importance',
                height=400,
                margin=dict(l=10, r=10, t=30, b=10),
                plot_bgcolor="white",
                paper_bgcolor="rgba(0,0,0,0)",
                xaxis=dict(
                    showline=True,
                    linewidth=1,
                    linecolor="black"
                ),
                yaxis=dict(
                    showline=True,
                    linewidth=1,
                    linecolor="black"
                )
            )

            fig_rf.update_xaxes(
                tickmode="linear",
                tick0=0,
                dtick=1,
                showgrid=True,
                gridwidth=1
            )

            st.plotly_chart(fig_rf, use_container_width=True)
        

            

        st.success("ğŸ’¡ **Top-40 Feature Set**ì´ ëª¨ë¸ ì„±ëŠ¥ê³¼ ì•ˆì •ì„± ê°„ ìµœì  ê· í˜•ì„ ì œê³µí•¨ì„ í™•ì¸í–ˆìŠµë‹ˆë‹¤.")

        # âœ… 1í–‰ ì˜¤ë¥¸ìª½: Top-10 ê·¸ë˜í”„
        with col2:
            st.markdown(f"##### Top-10 Influential Sensors (Based on **{importance_method}**)")

            if importance_method == "Lasso":
                top_10_df = data['importance_lasso'].head(10)
            else:
                top_10_df = data['importance_rf'].head(10)

            top_10_df = top_10_df.sort_values('importance', ascending=True)

            fig_top10 = go.Figure(go.Bar(
                x=top_10_df['importance'],
                y=top_10_df['feature'],
                orientation='h',
                # ì¤‘ìš”ë„ê°€ ë†’ì„ìˆ˜ë¡ ìƒ‰ì´ ì§„í•´ì§€ê²Œ
                marker=dict(
                    color=top_10_df['importance'],
                    colorscale="Blues"
                ),
                text=top_10_df['importance'],
                textposition='outside'
            ))

            fig_top10.update_layout(
                title=f'{importance_method} ê¸°ë°˜ ìƒìœ„ 10ê°œ ì„¼ì„œ',
                xaxis_title='Importance (count ê¸°ë°˜)',
                yaxis_title='Sensor ID',
                height=500,
                plot_bgcolor="white",
                paper_bgcolor="rgba(0,0,0,0)",
                xaxis=dict(
                    showline=True,
                    linewidth=1,
                    linecolor="black"
                ),
                yaxis=dict(
                    showline=True,
                    linewidth=1,
                    linecolor="black"
                )
            )

            fig_top10.update_xaxes(
                tickmode="linear",
                tick0=0,
                dtick=1,
                showgrid=True,
                gridwidth=1
            )

            st.plotly_chart(fig_top10, use_container_width=True)

        # âœ… 1í–‰ ì•„ë˜ êµ¬ë¶„ì„ 
        st.markdown("---")

        # âœ… 2í–‰: ì•ˆì •ì„± ì ìˆ˜ ë¶„í¬ (ì „ì²´ í­)
        st.markdown("##### Feature Stability Score (Lasso vs RandomForest)")

        fig_stability = go.Figure()

        # Lasso Boxplot
        fig_stability.add_trace(go.Box(
            y=data['stability_scores']['Lasso'],
            name='Lasso',
            marker_color='royalblue',
            boxmean=True   # í‰ê· ì„  í‘œì‹œ
        ))

        # RandomForest Boxplot
        fig_stability.add_trace(go.Box(
            y=data['stability_scores']['RandomForest'],
            name='RandomForest',
            marker_color='lightskyblue',
            boxmean=True
        ))

        fig_stability.update_layout(
            title_text="ì•ˆì •ì„± ì ìˆ˜ ë¶„í¬ ë¹„êµ",
            yaxis_title="Stability Score",
            height=450,
            plot_bgcolor="white",
            paper_bgcolor="rgba(0,0,0,0)",
            margin=dict(l=20, r=20, t=50, b=20)
        )

        st.plotly_chart(fig_stability, use_container_width=True)

        st.info(
            "RandomForestëŠ” Lassoë³´ë‹¤ ì•ˆì •ì„± ì ìˆ˜ê°€ ë†’ì•„ ë” ì¼ê´€ì ìœ¼ë¡œ Featureë¥¼ ì„ íƒí•˜ëŠ” ê²½í–¥ì„ ë³´ì…ë‹ˆë‹¤."
        )

    # ---------------------------------------------------------------------------------
    # TAB 2: Baseline Model
    # ---------------------------------------------------------------------------------
    with tab2:
        st.subheader("Baseline Model")
        st.markdown("Model Aì™€ Bì˜ Baseline ì„±ëŠ¥ì„ ë‹¤ì–‘í•œ ê´€ì ì—ì„œ ë¹„êµ ë¶„ì„í•©ë‹ˆë‹¤.")
        st.markdown("---")

        st.markdown("###  Baseline ì‹¤í—˜ ì„¤ê³„ (Experiment Setup)")
        st.write("")

        # --- ì¹´ë“œ ìŠ¤íƒ€ì¼ CSS (Advancedì—ì„œ ì´ë¯¸ ì„ ì–¸í–ˆìœ¼ë©´ ìƒëµ ê°€ëŠ¥) ---
        st.markdown("""
        <style>
        .info-card {
            background-color: #ffffff;
            padding: 18px 20px;
            border-radius: 12px;
            box-shadow: 0px 2px 6px rgba(0,0,0,0.08);
            margin-bottom: 12px;
            border-left: 6px solid #4A90E2;
        }
        .info-title {
            font-weight: 700;
            font-size: 16px;
            margin-bottom: 6px;
        }
        .info-text {
            font-size: 14px;
            line-height: 1.5;
        }
        </style>
        """, unsafe_allow_html=True)

        # ------- 1ì¤„ (ë°ì´í„° ë¶„í•  / ë¶ˆê· í˜• ì²˜ë¦¬) -------
        bcol1, bcol2 = st.columns(2)

        with bcol1:
            st.markdown("""
            <div class="info-card">
                <div class="info-title">â‘  ë°ì´í„° ë¶„í•  ë°©ì‹</div>
                <div class="info-text">
                    â€¢ Train 80% / Test 20% (Hold-out, random_state=42)<br>
                    â€¢ numpy / sklearn ë“± ì£¼ìš” ë‚œìˆ˜ ì—°ì‚°ì— ë™ì¼í•œ ì‹œë“œ(42)ë¥¼ ì ìš©
                </div>
            </div>
            """, unsafe_allow_html=True)

        with bcol2:
            st.markdown("""
            <div class="info-card">
                <div class="info-title">â‘¡ ë¶ˆê· í˜• ì²˜ë¦¬ ê¸°ë²•</div>
                <div class="info-text">
                    â€¢ RUS<br>
                    â€¢ SMOTE<br>
                    â€¢ SMOTE + Tomek Links
                </div>
            </div>
            """, unsafe_allow_html=True)

        # ------- 2ì¤„ (í‰ê°€ ì§€í‘œ / ë¹„êµ ëª¨ë¸) -------
        bcol3, bcol4 = st.columns(2)

        with bcol3:
            st.markdown("""
            <div class="info-card">
                <div class="info-title">â‘¢ í‰ê°€ ì§€í‘œ</div>
                <div class="info-text">
                    â€¢ Recall<br>
                    â€¢ F1-score<br>
                    â€¢ AUC-PR
                </div>
            </div>
            """, unsafe_allow_html=True)

        with bcol4:
            st.markdown("""
            <div class="info-card">
                <div class="info-title">â‘£ ë¹„êµ ëª¨ë¸</div>
                <div class="info-text">
                    â€¢ Logistic Regression<br>
                    â€¢ Linear SVM<br>
                    â€¢ Decision Tree
                </div>
            </div>
            """, unsafe_allow_html=True)


        # ---------------------------------------
        # 1í–‰: Model Summary + Heatmap
        # ---------------------------------------
        col1, col2 = st.columns(2)

        with col1:
            st.markdown("##### ëª¨ë¸ ìš”ì•½ (Model Summary)")
            selected_baseline_model = st.selectbox("ëª¨ë¸ ì„ íƒ", ["Model A", "Model B"])
            
            if selected_baseline_model == "Model A":
                st.markdown("""
                - **Scaling:** RobustScaler  
                - **Model Type:** LogisticRegression  
                - **ì£¼ìš” ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸:** Median Imputation â†’ Robust Scaling â†’ Feature Top-40 ì„ íƒ  
                - **ëª¨ë¸ ì¥ì :** ì´ìƒì¹˜ì— ëœ ë¯¼ê°í•˜ì—¬ ì„¼ì„œ ë¶„í¬ê°€ ì¹˜ìš°ì¹œ í™˜ê²½ì—ì„œë„ ì„±ëŠ¥ì´ ì•ˆì •ì ì…ë‹ˆë‹¤. ì¬í•™ìŠµ ì‹œ ìŠ¤ì¼€ì¼ ë³€í™”ì— ê°•ì¸í•´ ë¡œë²„ìŠ¤íŠ¸í•œ Baseline ëª¨ë¸ë¡œ í™œìš© ê°€ëŠ¥í•©ë‹ˆë‹¤.  
                - **ëª¨ë¸ í•œê³„:** í‰ê·  ì •ë³´ë¥¼ í™œìš©í•˜ì§€ ì•Šì•„ ì™„ë§Œí•œ ë³€ë™ì„ ì„¸ë°€í•˜ê²Œ ë°˜ì˜í•˜ëŠ” ë°ëŠ” ë‹¤ì†Œ ë¶ˆë¦¬í•  ìˆ˜ ìˆê³ , RobustScaler ì‚¬ìš©ìœ¼ë¡œ StandardScaler ëŒ€ë¹„ í•´ì„ì´ ì§ê´€ì ì´ì§€ ì•Šì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.  
                """)
            else:
                st.markdown("""
                - **Scaling:** StandardScaler  
                - **Model Type:** LogisticRegression  
                - **ì£¼ìš” ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸:** Mean Imputation â†’ Standard Scaling â†’ Feature Top-40 ì„ íƒ  
                - **ëª¨ë¸ ì¥ì :** êµ¬ì¡°ê°€ ë‹¨ìˆœí•˜ê³  ê³„ì‚° ë¹„ìš©ì´ ì ìœ¼ë©°, ì„ í˜• ê´€ê³„ í•´ì„ì— ìš©ì´í•©ë‹ˆë‹¤. í‰ê· Â·ë¶„ì‚° ê¸°ë°˜ StandardScalerë¥¼ ì‚¬ìš©í•´ í•´ì„ì´ ì§ê´€ì ì…ë‹ˆë‹¤.  
                - **ëª¨ë¸ í•œê³„:** ì´ìƒì¹˜ì— ë¯¼ê°í•˜ì—¬ ì„¼ì„œ ê°’ì— í° íŠ€ëŠ” ê°’ì´ ì¡´ì¬í•  ë•Œ ì„±ëŠ¥ì´ ë¶ˆì•ˆì •í•´ì§ˆ ìˆ˜ ìˆê³ , ë³µì¡í•œ ë¹„ì„ í˜• ê´€ê³„ë¥¼ ì¶©ë¶„íˆ í‘œí˜„í•˜ëŠ” ë° í•œê³„ê°€ ìˆìŠµë‹ˆë‹¤.  
                """)

        with col2:
            st.markdown("##### ë¶ˆê· í˜• ì²˜ë¦¬ ê¸°ë²•ë³„ ëª¨ë¸ ì„±ëŠ¥ ë¹„êµ")

            # ğŸ“Œ 1) ì§€í‘œ ì„ íƒ UI
            metric = st.selectbox("ì§€í‘œ ì„ íƒ", ["F1-score", "Recall", "AUC-PR"])

            # ğŸ“Œ 2) ëª¨ë¸ ì„ íƒê°’ì— ë”°ë¼ íˆíŠ¸ë§µ ê·¸ë£¹ ì„ íƒ
            if selected_baseline_model == "Model A":
                heatmap_dict = data["baseline_heatmap_a"]
            else:
                heatmap_dict = data["baseline_heatmap_b"]

            # ğŸ“Œ 3) ëª¨ë¸ + ì§€í‘œ ì¡°í•©ìœ¼ë¡œ íˆíŠ¸ë§µ ì„ íƒ
            heatmap_df = heatmap_dict[metric]

            # ğŸ“Œ 4) íˆíŠ¸ë§µ ì¶œë ¥
            fig_heatmap = go.Figure(data=go.Heatmap(
                z=heatmap_df.values,
                x=heatmap_df.columns,
                y=heatmap_df.index,
                colorscale='Blues',
                text=heatmap_df.applymap(lambda x: f'{x:.3f}'),
                texttemplate="%{text}",
                textfont={"size": 12}
            ))

            fig_heatmap.update_layout(
                title=f'{metric} ê¸°ì¤€ ì„±ëŠ¥ íˆíŠ¸ë§µ ({selected_baseline_model})',
                height=300
            )

            st.plotly_chart(fig_heatmap, use_container_width=True)


        # ---------------------------------------
        # êµ¬ë¶„ì„ 
        # ---------------------------------------
        st.markdown("---")

        # ---------------------------------------
        # 2í–‰: Bar Chart + Summary Metrics
        # ---------------------------------------
       

        # ==============================
        # ğŸ”¹ Baseline Model A vs B ì„¹ì…˜
        # ==============================

        # 0) Baseline ì„±ëŠ¥ ë°ì´í„° & ê·¸ë˜í”„ ì¤€ë¹„ (ë ˆì´ì•„ì›ƒ ë°”ê¹¥ì—ì„œ ë¨¼ì €)
        baseline_perf = data["baseline_perf"]  # Metric, Model A, Model B ì»¬ëŸ¼ ìˆìŒ

        # --- ë§‰ëŒ€ ê·¸ë˜í”„ ìƒì„± ---
        fig_baseline = go.Figure()
        for model_name in ["Model A", "Model B"]:
            fig_baseline.add_trace(
                go.Bar(
                    x=baseline_perf["Metric"],
                    y=baseline_perf[model_name],
                    name=model_name,
                    text=[f"{v:.3f}" for v in baseline_perf[model_name]],
                    textposition="auto",
                )
            )

        fig_baseline.update_layout(
            barmode="group",
            xaxis_title="Metric",
            yaxis_title="Score",
            legend_title="Model",
            height=350,
        )

        # --- Metric ê°’ êº¼ë‚´ê³  ì¦ê° ê³„ì‚° ---
        def get_metric(metric_name):
            row = baseline_perf[baseline_perf["Metric"] == metric_name].iloc[0]
            a = float(row["Model A"])
            b = float(row["Model B"])
            return a, b

        recall_a, recall_b = get_metric("Recall")
        f1_a, f1_b = get_metric("F1-Score")
        auc_a, auc_b = get_metric("AUC-PR")

        def diff_and_rate(a, b):
            diff = b - a
            rate = (diff / a * 100) if a != 0 else 0.0
            return diff, rate

        rec_diff, rec_rate = diff_and_rate(recall_a, recall_b)
        f1_diff, f1_rate = diff_and_rate(f1_a, f1_b)
        auc_diff, auc_rate = diff_and_rate(auc_a, auc_b)

        # 1) ì´ì „ ì„¹ì…˜ê³¼ì˜ ê°„ê²©
        st.markdown("<div style='margin-top:40px'></div>", unsafe_allow_html=True)

        # 2) ì œëª© ì¤„ (ì™¼ìª½/ì˜¤ë¥¸ìª½)
        title_col1, title_col2 = st.columns([1.2, 1])

        with title_col1:
            st.markdown("### Baseline Model A vs Model B Performance")

        with title_col2:
            st.markdown("### Performance Summary â€“ Baseline")

        # 3) ë‚´ìš© ì¤„ (ì™¼ìª½: ê·¸ë˜í”„, ì˜¤ë¥¸ìª½: metric ì¹´ë“œ)
        col1, col2 = st.columns([1.2, 1])

        # ğŸ”¸ ì™¼ìª½: ê·¸ë˜í”„
        with col1:
            st.markdown("<div style='margin-top:20px'></div>", unsafe_allow_html=True)
            st.plotly_chart(fig_baseline, use_container_width=True)

        # ğŸ”¸ ì˜¤ë¥¸ìª½: metric ì¹´ë“œ + Best Combination
        with col2:
            # ğŸ‘‰ ì„¸ë¡œë¡œ í•˜ë‚˜ì”© ë‚˜ì—´í•˜ë˜ metricì€ ì‚­ì œí•˜ê³ , ê°€ë¡œ 3ê°œë§Œ ì‚¬ìš©
            c1, c2_, c3 = st.columns(3)

            with c1:
                st.metric(
                    label="Recall (Baseline)",
                    value=f"{recall_b:.3f}",
                    delta=f"{rec_diff:+.3f} ({rec_rate:+.1f}%)"
                )

            with c2_:
                st.metric(
                    label="F1-Score (Baseline)",
                    value=f"{f1_b:.3f}",
                    delta=f"{f1_diff:+.3f} ({f1_rate:+.1f}%)"
                )

            with c3:
                st.metric(
                    label="AUC-PR (Baseline)",
                    value=f"{auc_b:.3f}",
                    delta=f"{auc_diff:+.3f} ({auc_rate:+.1f}%)"
                )

            st.write("")  # ì—¬ë°±

            # === ì—¬ê¸°ê°€ Performance Summary â€“ Baseline 3ê°œ metric ë°‘ ===
            st.markdown("### ğŸ† Baseline Best Combination ìš”ì•½")

            col_a, col_b = st.columns(2)

            with col_a:
                st.markdown(
                    """
                    <div style='background:#F8FAFF; padding:18px 20px; border-radius:12px;
                                border:1px solid #E1ECFF; box-shadow:0 2px 6px rgba(0,0,0,0.03);'>
                    <h4 style='margin:0 0 6px;'>Model A (Baseline)</h4>
                    <p style='margin:0 0 4px;'><b>Best ì¡°í•©:</b> RUS + DecisionTree</p>
                    <ul style='margin:8px 0 0 18px; padding:0;'>
                        <li><b>Recall:</b> 0.6667</li>
                        <li><b>F1-Score:</b> 0.1830</li>
                        <li><b>AUC-PR:</b> 0.0930</li>
                    </ul>
                    </div>
                    """,
                    unsafe_allow_html=True,
                )

            with col_b:
                st.markdown(
                    """
                    <div style='background:#FFF8F2; padding:18px 20px; border-radius:12px;
                                border:1px solid #FFE0C2; box-shadow:0 2px 6px rgba(0,0,0,0.03);'>
                    <h4 style='margin:0 0 6px;'>Model B (Baseline)</h4>
                    <p style='margin:0 0 4px;'><b>Best ì¡°í•©:</b> RUS + LinearSVM</p>
                    <ul style='margin:8px 0 0 18px; padding:0;'>
                        <li><b>Recall:</b> 0.8095</li>
                        <li><b>F1-Score:</b> 0.2411</li>
                        <li><b>AUC-PR:</b> 0.2142</li>
                    </ul>
                    </div>
                    """,
                    unsafe_allow_html=True,
                )

                st.divider()  # ğŸ‘ˆ ê°€ë¡œì„  ê¸‹ê¸°
                
            # 5) í•œ ì¤„ ìš”ì•½ Insight
        st.info(
                "Baseline ì¡°ê±´ì—ì„œ Model BëŠ” Recall, F1-score, AUC-PR ì „ ì§€í‘œì—ì„œ "
                "Model A ëŒ€ë¹„ ì„±ëŠ¥ í–¥ìƒì„ ë³´ì…ë‹ˆë‹¤. íŠ¹íˆ AUC-PRì€ ì•½ "
                f"{auc_rate:.1f}% ì¦ê°€í•˜ì—¬ ë¶ˆê· í˜• ë°ì´í„° í™˜ê²½ì—ì„œ ë” ì•ˆì •ì ì¸ ì˜ˆì¸¡ ì„±ëŠ¥ì„ ì œê³µí•©ë‹ˆë‹¤."
            )


        # ğŸ”½ ê²°ë¡  ì•„ë˜ë¡œ ë‚´ë¦¬ê¸°
        st.markdown("<div style='margin-top:60px;'></div>", unsafe_allow_html=True)

    # ---------------------------------------------------------------------------------
    # TAB 3: Advanced Model
    # ---------------------------------------------------------------------------------
    with tab3:
        st.subheader("Advanced Model")
        st.markdown("Baseline ëŒ€ë¹„ Advanced ëª¨ë¸ì˜ êµ¬ì„±ê³¼ ì„±ëŠ¥ì„ ë¶„ì„í•˜ê³ , ìµœì¢… ê²°ë¡ ì„ ë„ì¶œí•©ë‹ˆë‹¤.")
        st.markdown("---")

        st.markdown("###  Advanced Model ì‹¤í—˜ ì„¤ê³„ (Experiment Setup)")
        st.write("")

        # CSS ìŠ¤íƒ€ì¼ (ì¹´ë“œ UI)
        st.markdown("""
        <style>
        .info-card {
            background-color: #ffffff;
            padding: 18px 20px;
            border-radius: 12px;
            box-shadow: 0px 2px 6px rgba(0,0,0,0.08);
            margin-bottom: 12px;
            border-left: 6px solid #4A90E2;
        }
        .info-title {
            font-weight: 700;
            font-size: 16px;
            margin-bottom: 6px;
        }
        .info-text {
            font-size: 14px;
            line-height: 1.5;
        }
        </style>
        """, unsafe_allow_html=True)

        # ------- 1ì¤„ -------
        col1, col2 = st.columns(2)

        with col1:
            st.markdown("""
            <div class="info-card">
                <div class="info-title">â‘  ë°ì´í„° ë¶„í• </div>
                <div class="info-text">
                    â€¢ Train 80% / Test 20%<br>
                    â€¢ random_state = 42
                </div>
            </div>
            """, unsafe_allow_html=True)

        with col2:
            st.markdown("""
            <div class="info-card">
                <div class="info-title">â‘¡ ì „ì²˜ë¦¬ ë°©ì‹</div>
                <div class="info-text">
                    â€¢ Model A: Median + RobustScaler<br>
                    â€¢ Model B: Mean + StandardScaler
                </div>
            </div>
            """, unsafe_allow_html=True)

        # ------- 2ì¤„ -------
        col3, col4 = st.columns(2)

        with col3:
            st.markdown("""
            <div class="info-card">
                <div class="info-title">â‘¢ ë¶ˆê· í˜• ì²˜ë¦¬ ê¸°ë²•</div>
                <div class="info-text">
                    â€¢ RUS<br>
                    â€¢ SMOTE<br>
                    â€¢ SMOTE + Tomek Links
                </div>
            </div>
            """, unsafe_allow_html=True)

        with col4:
            st.markdown("""
            <div class="info-card">
                <div class="info-title">â‘£ ëª¨ë¸ ì¢…ë¥˜</div>
                <div class="info-text">
                    â€¢ RandomForest<br>
                    â€¢ LightGBM<br>
                    â€¢ XGBoost<br>
                    â€¢ CatBoost
                </div>
            </div>
            """, unsafe_allow_html=True)

        # ------- 3ì¤„ -------
        col5, col6 = st.columns(2)

        with col5:
            st.markdown("""
            <div class="info-card">
                <div class="info-title">â‘¤ í‰ê°€ ì§€í‘œ</div>
                <div class="info-text">
                    â€¢ Recall<br>
                    â€¢ F1-score<br>
                    â€¢ AUC-PR
                </div>
            </div>
            """, unsafe_allow_html=True)

        with col6:
            st.markdown("""
            <div class="info-card">
                <div class="info-title">â‘¥ ìµœì¢… ì„ ì • ê¸°ì¤€</div>
                <div class="info-text">
                    â€¢ 1ìˆœìœ„: AUC-PR<br>
                    â€¢ 2ìˆœìœ„: F1-score
                </div>
            </div>
            """, unsafe_allow_html=True)


        # ============================================================
        # ğŸ”¹ Advanced Model â€“ ë¶ˆê· í˜• ì²˜ë¦¬/ëª¨ë¸ë³„ ì„±ëŠ¥ íˆíŠ¸ë§µ (Model A vs B)
        # ============================================================
        BASE_DIR = Path(__file__).resolve().parents[2]

        # 1) CSV ë¶ˆëŸ¬ì˜¤ê¸° (ê³ ê¸‰ ëª¨ë¸ Stage D ê²°ê³¼)
        path_a = r"C:\Users\seo58\OneDrive\ë°”íƒ• í™”ë©´\capstone02_project_final\capstone02_project\results\stageD\holdout_metrics_summary.csv"
        path_b = r"C:\Users\seo58\OneDrive\ë°”íƒ• í™”ë©´\capstone02_project_final\capstone02_project\results\stageD\advanced_results_youngeun.csv"

        df_a = pd.read_csv(path_a)  # Model A (median pipeline)
        df_b = pd.read_csv(path_b)  # Model B (mean pipeline)

        # Model B ìª½ì€ ì»¬ëŸ¼ëª…ì´ Samplerë¼ì„œ Samplingìœ¼ë¡œ í†µì¼
        df_b = df_b.rename(columns={"Sampler": "Sampling"})

        # ğŸ”¹ AUC-PR ê¸°ì¤€ ê³ ê¸‰ ëª¨ë¸ Best Combination (A, B ê°ê°)
        best_a = df_a.sort_values("AUC_PR", ascending=False).iloc[0]
        best_b = df_b.sort_values("AUC_PR", ascending=False).iloc[0]

        # ğŸ”¹ Performance Summary â€“ Advanced ì—ì„œ ì“¸ ìš”ì•½ í…Œì´ë¸”
        advanced_perf_df = pd.DataFrame({
            "Metric": ["Recall", "F1-Score", "AUC-PR"],
            "Model A": [best_a["Recall"], best_a["F1"], best_a["AUC_PR"]],
            "Model B": [best_b["Recall"], best_b["F1"], best_b["AUC_PR"]],
        })

        # 2) ì§€í‘œ ì„ íƒ (F1 / Recall / AUC-PR íˆíŠ¸ë§µ)
        metric_label_map = {
            "Recall": "Recall",
            "F1-score": "F1",
            "AUC-PR": "AUC_PR",
        }

        selected_label = st.selectbox(
            "ì§€í‘œ ì„ íƒ",
            list(metric_label_map.keys()),
            index=1,   # ê¸°ë³¸ê°’: F1-score
        )
        metric_col = metric_label_map[selected_label]

        st.markdown(f"#### {selected_label} ê¸°ì¤€ ì„±ëŠ¥ íˆíŠ¸ë§µ (Model A vs Model B)")

        # 3) í”¼ë²—í…Œì´ë¸” ë§Œë“¤ê¸° (í–‰=Sampling, ì—´=Model)
        pivot_a = df_a.pivot(index="Sampling", columns="Model", values=metric_col)
        pivot_b = df_b.pivot(index="Sampling", columns="Model", values=metric_col)

        # 4) ë‘ íˆíŠ¸ë§µì´ ê°™ì€ ìƒ‰ ë²”ìœ„ë¥¼ ì“°ë„ë¡ min/max ê³µí†µ ì„¤ì •
        zmin = min(pivot_a.min().min(), pivot_b.min().min())
        zmax = max(pivot_a.max().max(), pivot_b.max().max())

        # ==========================
        # ì¢Œìš° 2ì—´ ë ˆì´ì•„ì›ƒ (íˆíŠ¸ë§µ)
        # ==========================
        col_left, col_right = st.columns(2)

        # ì™¼ìª½: Model A íˆíŠ¸ë§µ
        with col_left:
            st.markdown("##### Model A")

            fig_a = go.Figure(
                data=go.Heatmap(
                    z=pivot_a.values,
                    x=pivot_a.columns.tolist(),     # ëª¨ë¸ë“¤
                    y=pivot_a.index.tolist(),       # Sampling ë°©ë²•
                    colorscale="Blues",
                    zmin=zmin,
                    zmax=zmax,
                    text=np.round(pivot_a.values, 3),
                    texttemplate="%{text}",
                    colorbar=dict(title=selected_label),
                )
            )
            fig_a.update_layout(
                height=600,
                margin=dict(l=60, r=40, t=60, b=80),
                xaxis_title="Model",
                yaxis_title="Sampling Method",
                coloraxis_colorbar=dict(
                    len=0.8,
                    thickness=15,
                )
            )

            st.plotly_chart(fig_a, use_container_width=True)

        # ì˜¤ë¥¸ìª½: Model B íˆíŠ¸ë§µ
        with col_right:
            st.markdown("##### Model B")

            fig_b = go.Figure(
                data=go.Heatmap(
                    z=pivot_b.values,
                    x=pivot_b.columns.tolist(),
                    y=pivot_b.index.tolist(),
                    colorscale="Blues",
                    zmin=zmin,
                    zmax=zmax,
                    text=np.round(pivot_b.values, 3),
                    texttemplate="%{text}",
                    colorbar=dict(title=selected_label),
                )
            )
            fig_b.update_layout(
                height=600,
                margin=dict(l=40, r=60, t=60, b=80),
                xaxis_title="Model",
                yaxis_title="Sampling Method",
                coloraxis_colorbar=dict(
                    len=0.8,
                    thickness=15,
                )
            )

            st.plotly_chart(fig_b, use_container_width=True)

        # ============================================================
        # ğŸ”¹ Advanced ì„±ëŠ¥ ìš”ì•½ (ë¼ì¸ê·¸ë˜í”„ + ì¹´ë“œ + Best Combination)
        # ============================================================

        col1, col2 = st.columns(2)

        # â¬…ï¸ ì™¼ìª½: Advanced ì„±ëŠ¥ Line Chart (A vs B)
        with col1:
            st.markdown("##### Advanced Model â€“ A vs B Performance")

            fig_adv_perf = go.Figure()

            # Model A Line
            fig_adv_perf.add_trace(go.Scatter(
                x=advanced_perf_df['Metric'],
                y=advanced_perf_df['Model A'],
                mode='lines+markers',
                name='Model A (Adv)',
                line=dict(color='darkgrey', width=3),
                marker=dict(size=10)
            ))

            # Model B Line
            fig_adv_perf.add_trace(go.Scatter(
                x=advanced_perf_df['Metric'],
                y=advanced_perf_df['Model B'],
                mode='lines+markers',
                name='Model B (Adv)',
                line=dict(color='royalblue', width=3),
                marker=dict(size=10)
            ))

            fig_adv_perf.update_layout(
                title='Advanced ì„±ëŠ¥ ë¹„êµ (AUC-PR ê¸°ì¤€ Best ì¡°í•©)',
                yaxis_title='Score',
                xaxis_title='Metric',
                height=450,
                legend=dict(orientation="h", yanchor="bottom", y=-0.3),
                margin=dict(l=60, r=20, t=60, b=80)
            )        
            
            st.plotly_chart(fig_adv_perf, use_container_width=True)

        # â¡ï¸ ì˜¤ë¥¸ìª½: Metric ì¹´ë“œ ìš”ì•½ + Best Combination ì¹´ë“œ
        with col2:
            st.markdown("##### Performance Summary â€“ Advanced")
            st.write("")

            perf_pivot = advanced_perf_df.set_index('Metric')

            recall_a_adv = float(perf_pivot.loc['Recall',   'Model A'])
            recall_b_adv = float(perf_pivot.loc['Recall',   'Model B'])
            f1_a_adv     = float(perf_pivot.loc['F1-Score', 'Model A'])
            f1_b_adv     = float(perf_pivot.loc['F1-Score', 'Model B'])
            auc_a_adv    = float(perf_pivot.loc['AUC-PR',   'Model A'])
            auc_b_adv    = float(perf_pivot.loc['AUC-PR',   'Model B'])

            # ì¦ê° ê³„ì‚° (B - A)
            def diff_rate(a, b):
                diff = b - a
                rate = (diff / a * 100) if a != 0 else 0.0
                return diff, rate

            rec_diff, rec_rate = diff_rate(recall_a_adv, recall_b_adv)
            f1_diff,  f1_rate  = diff_rate(f1_a_adv,     f1_b_adv)
            auc_diff, auc_rate = diff_rate(auc_a_adv,    auc_b_adv)

            c1, c2_m, c3 = st.columns(3)

            with c1:
                st.metric(
                    label="Recall (Advanced)",
                    value=f"{recall_b_adv:.3f}",
                    delta=f"{rec_diff:+.3f} ({rec_rate:+.1f}%)"
                )

            with c2_m:
                st.metric(
                    label="F1-Score (Advanced)",
                    value=f"{f1_b_adv:.3f}",
                    delta=f"{f1_diff:+.3f} ({f1_rate:+.1f}%)"
                )

            with c3:
                st.metric(
                    label="AUC-PR (Advanced)",
                    value=f"{auc_b_adv:.3f}",
                    delta=f"{auc_diff:+.3f} ({auc_rate:+.1f}%)"
                )

            st.write("")  # Summaryì™€ Best ì¡°í•© ì‚¬ì´ ì—¬ë°±

            # ğŸ† Advanced Best Combination ìš”ì•½ (ì—¬ê¸° ì¶”ê°€!)
            st.markdown("### ğŸ† Advanced Best Combination ìš”ì•½")
            st.write("")

            bc1, bc2 = st.columns(2)

            # Model A ì¹´ë“œ
            with bc1:
                st.markdown("""
                <div style="
                    background-color:#F6F9FF;
                    padding:20px;
                    border-radius:16px;
                    border:1px solid #E0E6F5;
                    ">
                    <h4>Model A (Advanced)</h4>
                    <p><b>Best ì¡°í•© (AUC-PR ê¸°ì¤€):</b> LightGBM + SMOTE</p>
                    <ul>
                        <li><b>Recall:</b> 0.238</li>
                        <li><b>F1-Score:</b> 0.303</li>
                        <li><b>AUC-PR:</b> 0.302</li>
                    </ul>
                </div>
                """, unsafe_allow_html=True)

            # Model B ì¹´ë“œ
            with bc2:
                st.markdown("""
                <div style="
                background-color:#FFF7EB;
                padding:20px;
                border-radius:16px;
                border:1px solid #F3E0B8;
                ">
                <h4>Model B (Advanced)</h4>
                <p><b>Best ì¡°í•© (AUC-PR ê¸°ì¤€):</b> LightGBM + SMOTE+Tomek</p>
                <ul>
                    <li><b>Recall:</b> 0.190</li>
                    <li><b>F1-Score:</b> 0.276</li>
                    <li><b>AUC-PR:</b> 0.218</li>
                </ul>
            </div>


                """, unsafe_allow_html=True)



        # ============================================================
        # Conclusion
        # ============================================================
            
        st.markdown("### Conclusion â€“ Advanced Model")
        st.write("")

        con_col1, con_col2 = st.columns(2)

        # ---------------- ê¸°ìˆ ì  ì„±ê³¼ ----------------
        with con_col1:
            st.markdown("""
            <div style='background-color:#E9F5E9; padding:18px; border-radius:10px; border-left:6px solid #7BC47F;'>
            <h4>ê¸°ìˆ ì  ì„±ê³¼ (Technical Achievements)</h4>
            <ul>
                <li><b>ëª¨ë¸ ë¹„êµ ê²°ê³¼</b>: LGBM + SMOTE ì¡°í•©ì´ AUC-PR ê¸°ì¤€ ê°€ì¥ ì•ˆì •ì  ì„±ëŠ¥ì„ ë³´ì˜€ìŠµë‹ˆë‹¤.</li>
                <li><b>ë¶ˆê· í˜• ë°ì´í„° ëŒ€ì‘</b>: SMOTEÂ·SMOTE+Tomek ì ìš© ì‹œ ì¼ë¶€ ê°œì„  íš¨ê³¼ê°€ ìˆì—ˆìœ¼ë‚˜, ì ˆëŒ€ ì„±ëŠ¥ì€ ê¸°ëŒ€ ìˆ˜ì¤€ì—ëŠ” ë¯¸ì¹˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.</li>
                <li><b>ìš´ì˜ ì•ˆì •ì„±</b>: LightGBM ëª¨ë¸ì€ ê°€ë²¼ìš´ êµ¬ì¡°ë¡œ ì¼ê´€ëœ ê²°ê³¼ë¥¼ ì œê³µí•˜ë©° ìš´ì˜ íš¨ìœ¨ì„±ì´ ë†’ì•˜ìŠµë‹ˆë‹¤.</li>
            </ul>
            </div>
            """, unsafe_allow_html=True)

        # ---------------- ë¹„ì¦ˆë‹ˆìŠ¤ ì„íŒ©íŠ¸ ----------------
        with con_col2:
            st.markdown("""
            <div style='background-color:#FFF9E6; padding:18px; border-radius:10px; border-left:6px solid #E2C275;'>
            <h4>ë¹„ì¦ˆë‹ˆìŠ¤ ì„íŒ©íŠ¸ (Business Impact)</h4>
            <ul>
                <li><b>ë¦¬ìŠ¤í¬ ìµœì†Œí™”</b>: Recall ìœ ì§€ë ¥ì€ í™•ë³´í–ˆì§€ë§Œ ì ˆëŒ€ ìˆ˜ì¹˜ê°€ ë‚®ì•„ ì¶”ê°€ ì„±ëŠ¥ ê°œì„ ì´ í•„ìš”í•œ ê²ƒìœ¼ë¡œ íŒë‹¨ë©ë‹ˆë‹¤.</li>
                <li><b>ë¹„ìš© ì ˆê°</b>: ëª¨ë¸ êµ¬ì¡°ëŠ” ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§ í™˜ê²½ì— ì í•©í•˜ì§€ë§Œ, ì˜¤íƒÂ·ë¯¸íƒ ê°œì„  ì—¬ì§€ê°€ ì¡´ì¬í•©ë‹ˆë‹¤.</li>
                <li><b>í–¥í›„ ì ìš©ì„±</b>: ê³ ê¸‰ ëª¨ë¸ ê²°ê³¼ë¥¼ ê¸°ë°˜ìœ¼ë¡œ <b>íŒŒìƒ í”¼ì²˜ + Model A/B Core Feature Union ê¸°ë°˜ ì¬í•™ìŠµ ì „ëµ</b>ì„ Stage Finalì—ì„œ ì ìš©í•˜ì—¬ ì‹¤ì‚¬ìš© ì„±ëŠ¥ í™•ë³´ë¥¼ ëª©í‘œë¡œ ì§„í–‰í–ˆìŠµë‹ˆë‹¤.</li>
            </ul>
            </div>
            """, unsafe_allow_html=True)

if __name__ == '__main__':
    render()    
    